---
title: "`r sprintf('Baseline (%s)', params$sex)`"
output: md_document
params:
  input_file: NULL
  # hlen: NULL
  # hlen_exactly: FALSE
  #sample_fraction: 1.0
  model: "dt"
  mode: "initial"
  sex: "both"
  id: NULL
  date: "2020-07-08"
  extra_id: NULL
  summary_table_file: NULL
  effect_size_table_file: NULL
  shap_value_table_file: NULL
  prediction_table_file: NULL
  Hb_cutoff_male: 135
  Hb_cutoff_female: 125
  predictive_variables: NULL
  hyperparameters: "filename"
  cores: 4
  iterations: 2000
  skip_train: FALSE
  compute_shap_values: TRUE
  create_datasets_bool: TRUE
  donor_specific_file: NULL
  dev: "cairo_pdf"  
tables: true 
---

  
```{r, echo=FALSE, message=FALSE}
message(sprintf(">>>>>>>>>> Baseline %s %s >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>", params$sex, knitr::opts_chunk$get("dev")))
```

```{r, results="asis", echo=FALSE, message=FALSE}
#cat(sprintf("# Baseline (%s)\n", params$sex))
```


<!-- <h2> Initialization </h2> -->
```{r Setup, setup = TRUE, echo=FALSE, message=FALSE, results="hide"}


suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(knitr))
suppressPackageStartupMessages(library(kableExtra))
suppressPackageStartupMessages(library(caret))
suppressPackageStartupMessages(library(tictoc))
suppressPackageStartupMessages(library(entropy))
suppressPackageStartupMessages(library(brms))
suppressPackageStartupMessages(library(ggmcmc))
suppressPackageStartupMessages(library(ggthemes))
suppressPackageStartupMessages(library(ggridges))
suppressPackageStartupMessages(library(ROCR))
suppressPackageStartupMessages(library(pROC))
suppressPackageStartupMessages(library(furrr))
suppressPackageStartupMessages(library(sn))
suppressPackageStartupMessages(library(tidyverse))

source("common.R")
source("enrich_deferrals_rf.R")

# This can measure time a chunk took to execute.
# Add chunk option time_it=TRUE to each chunk your want to measure.
knitr::knit_hooks$set(time_it = local({
  now <- NULL
  function(before, options) {
    if (before) {
      # record the current time before each chunk
      now <<- lubridate::now()
    } else {
      # calculate the time difference after a chunk
      res <- lubridate::now() - now
      # return a character string to show the time
      msg <- paste("Time for this code chunk to run:", as.numeric(res), units(res))
      message(msg)
      NULL   # Don't return the message so that it won't be printed to the resulting document.
    }
  }
}))


knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, results = "hide", time_it=TRUE)
#knitr::opts_chunk$set(echo=TRUE, message=TRUE)
#options(warn = 1)

if (knitr::opts_chunk$get("dev") == "pdf") {
  knitr::opts_chunk$set(dev="cairo_pdf")
  knitr::opts_current$set(dev="cairo_pdf")
}
message(paste0("Device is ", knitr::opts_chunk$get("dev"), "\n"))
message(paste0("Current device is ", knitr::opts_current$get("dev"), "\n"))
use_pdf <- knitr::opts_chunk$get("dev") %in% c("pdf", "cairo_pdf")
skip_train <- use_pdf  # Reuse the things computed for png output

message("Parameters are:")
for (name in names(params)) {
  message(sprintf("%s = ", name), params[[name]])
}

mode <- params$mode



#set.seed(123)

set_cores_options(params$cores)

# number_of_cores <- parallel::detectCores()
# if (!is.null(params$cores)) {
#   number_of_cores <- min(params$cores, number_of_cores)
#   options(mc.cores   = number_of_cores)   # This option is in package parallel
#   options(boot.ncpus = number_of_cores)   # For bootstrapping
# } else {
#   options(mc.cores   = number_of_cores)
#   options(boot.ncpus = number_of_cores)
# }



datadir = "../data/rdata/"

rawresultdir = "../data/raw_results/"   # I store plot objects and tables in this directory

# Id for a run. For example files in rawresultdir use this id as part of their name. 
# Probably I should add a possibility to download raw results from the web interface.
if (is.null(params$id)) {
  id <- paste(params$date, params$extra_id, sep="_") 
} else {
  id <- params$id
}

source("helper_functions.R")
source("validate_stan_fit.R")

data <- readRDS(params$input_file)

data <- data %>%
  mutate(days_to_previous_fb = as.double(days_to_previous_fb),
         donor = as.character(donor))   # For some reason this cannot be a factor



donor_variables = NULL
donor_specific_variables <- NULL


# Maybe this is not needed except for linear regression
# data <- filter_based_on_number_of_donations(data, params$hlen, params$hlen_exactly)


logger <- new_logger(prefix=sprintf("Baseline %s:", params$sex), file="../output/exclusions.txt", silent=use_pdf)
```



## Data description


### Variables used in prediction

```{r, echo=FALSE, results="markup"}
if (use_pdf) {
  kbl(descript, format="latex", booktabs=TRUE) %>%
  kableExtra::column_spec(1, latex_column_spec = "p{3.2cm}") %>%
  kableExtra::column_spec(2, latex_column_spec = "p{3cm}")   %>%
  kableExtra::column_spec(3, latex_column_spec = "p{2.5cm}") %>%
  kableExtra::column_spec(4, latex_column_spec = "p{6cm}")
} else {
  kbl(descript) %>% kable_styling()
}
```


```{r, echo=FALSE}
kable(donor_descript %>% filter(Variable %in% names(donor_specific_variables)))
```

```{r Descriptions, results="asis", echo=FALSE}
cat(sprintf("### Summary plots of variables (%s)\n", params$sex))
```


```{r Summary plots, echo = FALSE, results="hide"}
res <- create_summary_plots(data, donor_specific_variables, params$sex, descript, donor_descript)
```

```{r, fig.height = 10, fig.width = 7}
res[[1]]
```

```{r}
res[[2]]
```

```{r}
res[[3]]
```


```{r Partition and enrich, echo=FALSE}
# enriched_filename <- sprintf("%s/baseline-enriched-%s-%s.rds", datadir, params$model, params$sex)
# test_filename <- sprintf("%s/baseline-test-%s-%s.rds", datadir, params$model, params$sex)
# if (skip_train) {
#   enriched <- readRDS(enriched_filename)
#   test <- readRDS(test_filename)
# } else {
  debug <- TRUE
  
  donors <- ndonor(data)
  message(sprintf("Number of donors is %i\n", length(donors)))
  old_count <- nrow(data); old_count2 <- ndonor(data)
  
  #tmp <- old_split(data)
  tmp <- new_split(data, mode)
  train_orig <-tmp$train
  test <- tmp$test
  
  msg <- sprintf("Dropped %i / %i donations (%i / %i donors) due to taking training subsample\n", 
                  old_count - nrow(train_orig), old_count, old_count2 - ndonor(train_orig), old_count2)
  message(msg)
  print(logger, msg)
  message("Here")
  sink(file=stderr(), type="output"); summary(train_orig); sink()
  n <- length(unique(train_orig %>% group_by(donor) %>% filter(max(Hb_deferral) == 1) %>% ungroup() %>% pull(donor)))
  message(sprintf("%i donors have at least one deferral\n", n))
  #message(summary(train_orig))
  #if (debug) saveRDS(train_orig, file="/tmp/pre-enriched.rdata")
  
  # # enrich the data so that 50% of the donors have deferral as their last donation attempt
  # old_count <- nrow(train_orig); old_count2 <- ndonor(train_orig)
  # #sink(file=stderr(), type="output")
  # if (old_count2 >= 1000) {
  #   enriched <- enrich_deferrals_rf(train_orig, 0.5, seed=global_random_seed)  # truncates time series
  #   #sink()
  #   msg <- sprintf("Dropped %i / %i donations (%i / %i donors) due to enrichment\n", 
  #                   old_count - nrow(enriched), old_count, old_count2 - ndonor(enriched), old_count2)
  #   message(msg)
  #   print(logger, msg)
  #   #if (debug) save(enriched, file="/tmp/post-enriched.rdata")
  # } else {  # Don't enrich if less than 1000 donors
  #   message(sprintf("Skipped enrichment of train data, since number of donors %i is less than %i", old_count2, 1000))
  #   enriched <- train_orig
  # }
  # 
  # n <- length(unique(enriched %>% group_by(donor) %>% filter(max(Hb_deferral) == 1) %>% ungroup() %>% pull(donor)))
  # message(sprintf("%i donors have at least one deferral\n", n))
  # 
  # sink(file=stderr(), type="output"); summary(enriched); sink()
  # #if (debug) save(enriched, file="/tmp/enriched.rdata")
  # #enriched <- enriched %>% select(-FERRITIN_LAST_DATE)
  # #rm(train_orig)
  # 
  # saveRDS(enriched, enriched_filename)
#   saveRDS(test, test_filename)
# }
message("and here")
```

```{r Take the last events}
# helper <- function(data) {
#   data <- data %>% group_by(donor) %>%
#     dplyr::filter(n()>1) %>%  #Take out the ones with only one event 
#     slice_max(order_by = dateonly, n=1) %>%
#     ungroup()
# }
# 
# # Take only the last events
# enriched <- helper(enriched)
# test <- helper(test)
# sink(file=stderr(), type="output"); summary(enriched); sink()
# sink(file=stderr(), type="output"); summary(test); sink()
```

```{r Process train and validate sets further}


variables <- params$predictive_variables

variables <- c(variables, "Hb_deferral")

if (!is.null(donor_variables)) {
  variables <- c(variables, donor_variables)
}

sizes <- data_counts(train=train_orig, validate=test)

  
#Train
save(variables, train_orig, test, file=sprintf("/tmp/baseline-%s.rdata", params$sex))

logger2 <- logger
logger2$prefix <- paste(logger$prefix, "train:")
train <- additional_preprocess(train_orig, c(variables, "label"), logger=logger2)    # Label is needed if we will learn hyperparameters.


#Validate

logger2$prefix <- paste(logger$prefix, "test:")
validate <- additional_preprocess(test, c(variables, "Hb", "sex"), logger=logger2) # We want to include Hb and sex to the prediction result table
rm(logger2)


```


```{r Info about datasets, results="asis", echo=FALSE}
msg <- sprintf("The train set contains %i donations from %i donors.", nrow(train), nrow(train))
message(msg)
#cat(msg)
sink(file=stderr(), type="output"); summary(train); sink()

msg <- sprintf("The validate set contains %i donations from %i donors.", nrow(validate), nrow(validate))
message(msg)
#cat(msg)
sink(file=stderr(), type="output"); summary(validate); sink()


train_deferred <- train %>% filter(Hb_deferral == "Deferred")
validate_deferred <- validate %>% filter(Hb_deferral == "Deferred")
#cat(sprintf("The train set contains %i deferrals from %i donors.", nrow(train_deferred), nrow(train_deferred)))
#cat(sprintf("The validate set contains %i deferrals from %i donors.", nrow(validate_deferred), nrow(validate_deferred)))
kbl(sizes) %>% kable_styling()
rm(train_deferred)
rm(validate_deferred)
```

```{r Fit baseline model, results="asis", echo=FALSE}
logistic_regression <- function(data) {
  glm.fit <- glm(Hb_deferral ~ previous_Hb,
               data = data,
               family = binomial)
  return(glm.fit)  
}

train <- caret::upSample(x = train, y = train$Hb_deferral) %>% as_tibble() %>% select(-Class)

#up_train <- upSample(x = imbal_train[, -ncol(imbal_train)],
#                     y = imbal_train$Class)            


fit_filename <- sprintf("%s/baseline-fit-%s-%s.rds", datadir, params$model, params$sex)
if (skip_train) {
  fit <- readRDS(fit_filename)  
} else {
  fit <- logistic_regression(train)
  saveRDS(fit, fit_filename)
}
#fit
```

```{r Predict validate data, results="asis", echo=FALSE}
predict_baseline <- function(glm.fit, data, threshold = NULL) {
  glm.probs <- predict(glm.fit,
                      newdata = data,
                      type = "response")
  
  result <- tibble(score = glm.probs, 
                   original_value = data$Hb,
                   predicted_value = NA,
                   original_label = as.integer(data$Hb_deferral=="Deferred"),
                   previous_Hb = data$previous_Hb
                   )

  if (!is.null(threshold)) {  
    result <- result %>%
      mutate(predicted_label = as.integer(score >= threshold),
             f1_threshold = threshold,
             score_predicted_label = predicted_label)
  }
  
  return(result)
}

# optimize_threshold <- function(df) {
#     cp <- cutpointr::cutpointr(df$score, df$original_label, 
#                     direction="<=",   # Smaller values mean positive class 
#                     method = maximize_metric, metric = sum_sens_spec)
#     return(cp$optimal_cutpoint)
# }

enriched_result <- predict_baseline(fit, train %>% mutate(Hb=0))  # Add dummy Hb value to prevent a warning
# Optimize the probability threshold
cp <- get_optimal_cut_point(enriched_result$score, enriched_result$original_label, pos_class=1)

cp_filename <- sprintf("/tmp/cut_point_%s_%s.rds", params$model, params$sex)
saveRDS(cp, cp_filename)

f1_threshold <- cp$optimal_cutpoint
cat(sprintf("Train data F1 threshold is %.3f, FPR is %.3f, TPR is %.3f\n", f1_threshold, 1-cp$specificity, cp$sensitivity))
sink(file=stderr(), type="output"); cp; sink()

#threshold <- optimize_threshold(enriched_result)
enriched_result <- enriched_result %>%
  mutate(predicted_label = as.integer(score >= f1_threshold),
         f1_threshold = f1_threshold,
         score_predicted_label = predicted_label)
  
test_result <- predict_baseline(fit, validate, f1_threshold)
cp_validate <- get_optimal_cut_point(test_result$score, test_result$original_label, pos_class=1)
```



```{r clean up memory, echo = FALSE}
rm(data); invisible(gc())
```

### Train data cutoff plot

```{r}
summary(cp)
plot(cp)
plot_metric(cp, conf_lvl = 0.95)
```

### Validation data cutoff plot

```{r}
summary(cp_validate)
plot(cp_validate)
plot_metric(cp_validate, conf_lvl = 0.95)
```




## Results

```{r SHAP values, eval=params$compute_shap_values}
message(paste(colnames(train), collapse=" "))
message(paste(colnames(validate), collapse=" "))


shap_filename <- sprintf("/tmp/shap_values_%s_%s.rds", params$model, params$sex)
if (use_pdf) {     
  res <- readRDS(shap_filename)   # Already computed when creating png from the Rmd
} else {
  res <- compute_shap_values_fastshap(fit, validate, variables, seed=global_random_seed) 
  #res <- compute_shap_values(svmFit_roc$finalModel, train, validate, variables)
  saveRDS(res, shap_filename)
}

if (!is.null(res)) {
  if (!is.null(params$shap_value_table_file)) {
    write_csv(res, params$shap_value_table_file)   # Pass the table to the web app as well
  }

  variables_renamed <- FALSE
  
  shap_plot_rf <- plot_summary_shap_values(res, variables_renamed)
  shap_plot_rf2 <- plot_shap_values(res, variables_renamed)
  #ive_rf <- shapper::shap(exp_rf, new_observation = validate2[1,], nsamples=50)
  #plot(ive_rf)
  plot(shap_plot_rf)
  plot(shap_plot_rf2)
}
```


```{r Baseline results, results="hide"}
id <- sprintf("bl-%s", params$sex)


df <- tibble(id=id,
             model="bl",
             sex = validate$sex)

df <- bind_cols(df, test_result)

if (!is.null(params$prediction_table_file)) {
  write_csv(df %>% select(-previous_Hb), params$prediction_table_file)   # Pass the table to the web app as well
}



# Create the plots
results_baseline <- gather_results(df, Id=id, Model = "bl", Pretty="Baseline", Sex=params$sex)

# Show the plots
results_baseline$confusion_matrix_plot
results_baseline$roc_plot 
results_baseline$pr_plot


summary_table <- results_baseline$summary

# if (!is.null(params$effect_size_table_file)) {
#   write_csv(rrfFit.varimp, params$effect_size_table_file)   # Pass the table to the web app as well
# }



```


```{r Plot logistic regressions, results="asis", echo=FALSE}
get_inverse <- function(fit, threshold) {
  df <- tibble(previous_Hb = 100:200)
  
  df <- df %>% mutate(probability = predict(fit, newdata = df, type = "response"))  
  closest_probability <- df[[which.min(abs(df$probability - threshold)), "probability"]]
  previous_Hb <- df %>% filter(probability == closest_probability) %>% pull(previous_Hb)
  return(previous_Hb)
}

#saveRDS(df, sprintf("/tmp/df2-%s", params$sex))   # For debugging, remove
plot_logistic_regression <- function(df, title, previous_Hb) {
  g <- df %>% 
    ggplot(aes(x=previous_Hb, y=score)) + 
    geom_line() +
    geom_point(mapping=aes(x=previous_Hb, y=original_label)) +
    geom_vline(xintercept = previous_Hb) +
    labs(y="Probability", title=title)
  return(g)
}
previous_Hb <- get_inverse(fit, f1_threshold)
cat(sprintf("The previous_Hb value %.2f corresponds approximately to the threshold value %.2f\n", previous_Hb, f1_threshold))
enriched_g <- plot_logistic_regression(enriched_result, "enriched data", previous_Hb)
test_g <- plot_logistic_regression(test_result, "test data", previous_Hb)
```

```{r}
enriched_g
test_g
```




### Summary

```{r Summary}

if (!is.null(params$summary_table_file)) {
  write_csv(summary_table, params$summary_table_file)   # Pass the table to the web app as well
}

```

```{r Show summary table, results="markup"}
#cols <- c("Model"="Pretty", "Sex", "MAE (g / L)", "RMSE (g / L)", "MAE (mmol / L)", "RMSE (mmol / L)", "AUROC" = "AUROC value", "AUPR" = "AUPR value", "F1" = "F1 value")
cols <- c("Model"="Pretty", "Sex", "AUROC" = "AUROC value", "AUPR" = "AUPR value", "F1" = "F1 value")
kbl(summary_table %>% select(!!!cols), digits=3, format.args = list(digits=3)) %>% kable_styling()
```

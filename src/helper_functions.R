# General helper functions for the .Rmd notebook
# I'll try to comment what they'll do

suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(stringr))
suppressPackageStartupMessages(library(purrr))
suppressPackageStartupMessages(library(tibble))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(furrr))
suppressPackageStartupMessages(library(tictoc))
suppressPackageStartupMessages(library(caret))
suppressPackageStartupMessages(library(reshape2))

# A wrapper for load function.
# Instead of directly placing an object in the current scope with the stored name,
# return the object from the function.
# Works only if the rdata file contains a single object.
load_single <- function(filename) {
  names <- load(filename, verbose=FALSE)
  stopifnot(length(names) == 1)
  return(get(names))
}

ndonor <- function(df) {
  return(length(unique(df$donor)))  
}

is_hb_value_sane <- function(hb, hb_unit)
{
  if (hb_unit=="gperl") {
    return(hb > 100.0 && hb < 200.0)
  } else if (hb_unit=="gperdl") {
    return(hb > 10.0 && hb < 20.0)
  } else if (hb_unit =="mmolperl") { 
    return(hb < 10.0 && hb > 0.0)
  } else {
    stop(sprintf("Unknown hb unit %s\n", hb_unit))
  }
}

convert_hb_unit <- function(from, to, hb) {
  if (from == to)
    return(hb)
  #hb = parseFloat(hb);
  #cat(sprintf('In convert_hb_unit: from="%s" to="%s hb="%f"', from, to, hb))
  if (from=="gperl" && to=="gperdl") {
    return(hb/10.0)
  }  else if (from=="gperl" && to == "mmolperl") {
    return(hb * 0.01551 * 4)
  }  else if (from=="gperdl" && to == "gperl") {
    return(hb*10.0)
  }  else if (from=="gperdl" && to == "mmolperl") {
    return(hb * 10.0 * 0.01551 * 4)
  }  else if (from=="mmolperl" && to == "gperl") {
    return(hb / (0.01551 * 4))
  }  else if (from=="mmolperl" && to == "gperdl") {
    return(hb / (0.01551 * 4) / 10.0)
  } else {
    cat("Error: Unsupported units")
  }
}

paste_br <- function(vals) {
  # Creates correctly formated strings from median and mean values
  # generated by med_iq() and mean_sd()

  br1 <- paste(vals[2:length(vals)], collapse = ", ")
  br1 <- paste(paste(vals[1],'',sep=' '),"(",br1,")", sep='')
  return(br1)
}

med_iq <- function(vec) {
  # Returns the median and lower and upper quartiles
  # of a variable as a string in format:
  # median (lower, upper)

  # Can be used to create descriptive statistic tables

  med <- median(vec, na.rm = T)
  d <- quantile(vec, 1/4, na.rm = T)
  u <- quantile(vec, 3/4, na.rm = T)
  os <- paste_br(c(med,d,u))
  return(os)
}

# Returns filename and line number where this function was called.
# returns a list, unless fmtstring is specified
# level: 1 - caller of the caller of this function; 2 - its parent, 3 - its grand-parent etc.
# fmtstring: return format string: %f (function), %s (source file), %l (line)
# 
# example: str <- caller_info("Called from %f at %s#%l\n")
# !!! it won't work with e.g. cat(caller_info("Called from %f at %s#%l\n"))
# or cat(paste0(caller_info("Called from %f at %s#%l\n"))) !!!
caller_info <- function (fmtstring = NULL, level = 1) # https://stackoverflow.com/q/59537482/684229
{
  x <- .traceback(x = level + 1)
  
  i <- 1
  repeat { # loop for subexpressions case; find the first one with source reference
    srcref <- getSrcref(x[[i]])
    if (is.null(srcref)) {
      if (i < length(x)) {
        i <- i + 1
        next;
      } else {
        warning("caller_info(): not found\n")
        return (NULL)
      }
    }
    srcloc <- list(fun = getSrcref(x[[i+1]]), file = getSrcFilename(x[[i]]), line = getSrcLocation(x[[i]]))
    break;
  }
  
  if (is.null(fmtstring))
    return (srcloc)
  
  fmtstring <- sub("%f", paste0(srcloc$fun, collapse = ""), fmtstring)
  fmtstring <- sub("%s", srcloc$file, fmtstring)
  fmtstring <- sub("%l", srcloc$line, fmtstring)
  fmtstring
}

mean_sd <- function(vec) {
  # Returns the mean and standard deviation
  # of a variable as a string in format:
  # mean (sd)

  # Can be used to create descriptive statistic tables

  m <- round(mean(vec, na.rm = T), digits = 2)
  s <- round(sd(vec, na.rm = T), digits = 2)
  os <- paste_br(c(m,s))
  return(os)
}

get_season <- function(mon, southern_hemisphere=FALSE) {
  # Helper function for getting the season as a factor
  # if (mon %in% c(1,2,3,10,11,12)) {return(0)}
  # else if (mon %in% 4:9) {return(1)}
  # else {return(NULL)}
  warm_season <- mon %in% 4:9
  if (southern_hemisphere) {
    warm_season <- ! warm_season
  }
  return(as.numeric(warm_season))
}

extra_factor <- 2  # Andrew Gelman recommends scaling continuous variables by dividing by 2*stddev. This
                   # makes the binary variables to be on the same scale as the rest of the variables.

normalize_vector <- function(v, pmean=NULL, psd=NULL) {
  if (is.null(pmean)) pmean = mean(v, na.rm = TRUE)
  if (is.null(psd)) psd = sd(v, na.rm = TRUE)
  if (psd > 0.0) {
    return((v - pmean)/(extra_factor*psd))
  } else {
    return(v - pmean)
  }
}

denormalize_vector <- function(v, pmean, psd) {
  #if (is.null(pmean)) pmean = mean(v, na.rm = TRUE)
  #if (is.null(psd)) psd = sd(v, na.rm = TRUE)
  if (psd > 0.0) {
    return(v*(extra_factor*psd) + pmean)
  } else {
    return(v + pmean)    
  }
}

normalize <- function(df, columns) {
  # Z-Normalize the data set by columns
  #scale2 <- function(x) ((x - mean(x, na.rm = TRUE)) / (extra_factor*sd(x, na.rm = TRUE)))
  df <- mutate_at(df, .vars = columns, .funs = normalize_vector)
  return(df)
}

normalize_with_params <- function(df, means, sds) {
  #df <- as.data.frame(sapply(1:ncol(df), function(i) (df[,i] - means[i]) / (extra_factor*sds[i])))
  df <- as.data.frame(sapply(1:ncol(df), function(i) normalize_vector(df[,i], means[i], sds[i])))
  return(df)
}

denormalize <- function(df, original = NULL, columns = NULL, means = NULL, sds = NULL) {
  # Transform the normalized data into a comparable set by reversing the normalization
  
  # denorm_vec <- function(x, orig) (unlist(x) * (extra_factor*sd(unlist(orig))) + mean(unlist(orig)))
  
  #denorm_means <- function(x, m, s) (unlist(x) * (extra_factor*s) + m)
  denorm_means <- function(x, m, s) denormalize_vector(x, m, s)
  
  denorm2 <- function(x, orig) denormalize_vector(x, mean(orig), sd(orig))
  
  if (is.null(columns)) {
    #df <- denorm_vec(df, original)
    df <- denorm2(df, original)
  }
  # Check if df is a vector
  else if (is.vector(df)) {
    idx <- which(names(means) == columns[1])
    df <- denorm_means(df, means[idx], sds[idx])
  }
  else if (!is.null(means) & !is.null(sds)) {
    indices <- which(colnames(df) %in% columns)
    for (i in indices) {
      idx <- which(names(means) == colnames(df)[i])
      df[,i] <- denorm_means(df[[i]], means[idx], sds[idx])
    }
  }
  else {
    indices <- which(colnames(df) %in% columns)
    # Did not find a dplyr solution so let's go with for-loop
    for (i in indices) {
      df[,i] <- denorm2(df[[i]], original[[i]])
    }
  }
  return(df)
}

# Can be used to split data set to train and test parts in given fraction
split_set <- function(df, train_frac) {
  
  n.tab <- count(df, donor)
  part <- createDataPartition(n.tab$n, p = train_frac, list = F)
  dons <- n.tab$donor[part]
  train <- df %>%
    filter(donor %in% dons)
  dons <- n.tab$donor[-part]
  test <- df %>%
    filter(donor %in% dons)
  return(list("train" = train, "test" = test))
}

tvt_ratios <- c(train=0.64, validate=0.16, test=0.20)

# Can be used to split data set to train, validate, and test parts in given fraction
split_set3 <- function(df, seed, prob=tvt_ratios, donor_field = "KEY_DONOR") {
  message("In function split_set3")
  set.seed(seed)
  donors <- unique(df[[donor_field]])
  n <- length(donors)
  if (FALSE) {
    labels <- sample(factor(c("train", "validate", "test"), levels = c("train", "validate", "test")), 
                     size=n, replace = TRUE, prob=prob)
  } else {
    n1 <- as.integer(prob[1] * n)
    n2 <- as.integer(prob[2] * n)
    n3 <- n - n1 - n2
    labels <- c(rep("train", n1), rep("validate", n2), rep("test", n3))
    labels <- factor(sample(labels, size = n), levels=c("train", "validate", "test"))  # permute
  }
  # This is a cleaner solution than the one commented out.
  classes <- tibble({{donor_field}} := donors,
                    label=labels)
  return(inner_join(df, classes))
  # classes <- tibble(donor=donors,
  #                   label=labels)
  # return(classes %>% 
  #          inner_join(df, by=c(donor = {{donor_field}})) %>% 
  #          relocate(label, .after = last_col()) %>%
  #          rename({{donor_field}} := donor))
}

# Take a sample of donors
sample_set <- function(data, fraction) {
  donors <- unique(data$donor)
  a <- caret::createDataPartition(1:length(donors), p=fraction, list=FALSE)
  data <- data %>%
    filter(donor %in% donors[a])
  return(data)
}

# Take a sample while maintaining the train/validate/test division, and possibly also consider the sex.
# the parameter 'size' can be either a fraction or an integer. In the latter case,
# There are either 'size' donors or 'size' male donors and 'size' female donors in the returned dataset, depending on
# the stratify_by_sex parameter.
stratified_sample <- function(df, stratify_by_sex, size, seed,
                              donor_field = "KEY_DONOR",
                              sex_field   = "KEY_DONOR_SEX"
                              ) {
  message("In function stratified_sample")
  set.seed(seed)
  donors <- df %>% 
    select(all_of(donor_field), label, all_of(sex_field)) %>%
    distinct()
  #print(head(donors))
  if (size <= 1.0) {
    prop <- size
    if (stratify_by_sex) {
      g <- donors %>% 
        group_by(label, all_of(sex_field))
    } else {
      g <- donors %>% 
        group_by(label)
    }
    donors <- g %>%
      group_modify(function(df, id) slice_sample(df, prop=prop, replace=FALSE))  %>%
      ungroup()
  } else {
    size <- as.integer(size)
    counts <- enframe(tvt_ratios, "label", "count") %>%
      mutate(count=as.integer(count*size))
    r <- nrow(counts)
    counts[r, "count"] <- as.integer(size - sum(counts$count[1:(r-1)]))   # Make sure the result is exactly 'size' (or 2*size in the stratify_by_sex case)
    print(counts)    
    n <- n_distinct(df[[donor_field]])
    if (stratify_by_sex) {
      g <- donors %>%
        group_by(label, .data[[sex_field]]) 
    } else {
      g <- donors %>%
        group_by(label) 
    }
    strata <- g %>%
      group_split()
    keys <- g %>%
      group_keys() %>%
      inner_join(counts)
    #print(keys)
    donors <- map2_dfr(strata, keys$count, function(stratum, count) slice_sample(stratum, n=count))
  }
  result <- df %>% semi_join(donors, by=donor_field)
  return(result)
}

# Parameter 'exactly' specifies that time series are required to be exactly of length 'hlen'.
# If hlen < 0, then include donors who have donated at most |hlen| times.
# Otherwise, include donors who have donated at least hlen times.
# If exactly==TRUE, then include donors that have donated exactly hlen times.
filter_based_on_number_of_donations <- function(df, hlen, exactly=FALSE) {
  message("In filter_based_on_number_of_donations function")
  if (!is.null(hlen)) {
    at_most <- FALSE
    if (hlen < 0) {
      at_most <- TRUE
      hlen <- abs(hlen)
    }
    if (exactly) {
      df <- df %>%
        group_by(donor) %>%
        filter(n() == hlen) %>%
        ungroup()
    } else if (at_most) {
      df <- df %>%
        group_by(donor) %>%
        filter(n() <= hlen) %>%
        ungroup()
    } else {   # At least
      df <- df %>%
        group_by(donor) %>%
        filter(n() >= hlen) %>%
        ungroup()
    }
  }
  return(df)
}

stan_preprocess <- function(df, frac, normalize = TRUE) {
  # Function that makes the data ready for stan-analysis
  # This means getting rid of NA-values (meaning mostly first events),
  # normalizing the data and splitting it to test and train sets.
  warning("Preprocessing\n")
  table(df$previous_Hb_def)
  df <- df %>%
    filter(!is.na(Hb_first), !is.na(days_to_previous_fb),
           !is.na(Hb), !is.na(previous_Hb), first_event == FALSE,
           donat_phleb == 'K' | donat_phleb == '*' | donat_phleb == 'T',
           !is.na(previous_Hb_def)) %>%
    select(Hb, donor, days_to_previous_fb, age, previous_Hb_def, year, warm_season, Hb_first, consecutive_deferrals,
           recent_donations, recent_deferrals, previous_Hb, Hb_deferral, hour) %>%
    mutate(previous_Hb_def = as.integer(previous_Hb_def),
           warm_season = as.integer(warm_season), Hb_deferral = as.integer(Hb_deferral),
           original_Hb = Hb, days_to_previous_fb = log(days_to_previous_fb))
    
    
  # Calculate means here
  #print(head(df))
  df2 <- df %>% mutate(donor = as.integer(as.factor(donor))) # otherwise colMeans complains about non-numeric columns
  par_means <- colMeans(df2)
  par_sds <- apply(df2, 2, sd)
  rm(df2)
  
  # Normalize the data
  if (normalize) {
  df <- normalize(df, columns = c("Hb","days_to_previous_fb", "age", "year", "Hb_first", "consecutive_deferrals",
                                  "recent_donations","recent_deferrals", "previous_Hb","year","hour"))
  }

  test_train <- split_set(df, frac)

  test_train$train <- test_train$train %>%
    mutate(donor = as.integer(as.factor(donor)))

  test_train$test <- test_train$test %>%
    mutate(donor = as.integer(as.factor(donor)))

  train_dons <- test_train$train$donor
  test_dons <- test_train$test$donor

  y_train <- test_train$train$Hb
  y_test <- test_train$test$Hb
  original_Hb <- test_train$test$original_Hb

  train_labels <- test_train$train$Hb_deferral
  test_labels <- test_train$test$Hb_deferral

  # Remove previous Hb for state-dependence
  x_train <- test_train$train %>% select(days_to_previous_fb, age, previous_Hb_def, year, warm_season, Hb_first,
                                         consecutive_deferrals, recent_donations, recent_deferrals, hour)

  x_test <- test_train$test %>% select(days_to_previous_fb, age, previous_Hb_def, year, warm_season, Hb_first,
                                       consecutive_deferrals, recent_donations, recent_deferrals, hour)

  return(list(train_dons = train_dons,
              test_dons = test_dons,
              x_train = x_train,
              x_test = x_test,
              y_train = y_train,
              y_test = y_test,
              train_labels = train_labels,
              test_labels = test_labels,
              original_Hb = original_Hb,
              par_means = par_means,
              par_sds = par_sds))
}

stan_preprocess_icp <- function(df, frac, normalize = TRUE) {
  # Does mostly same thing as normal stan-preprocessing function.
  # Main exception is that this returns first Hb-values so that first events can be used
  # with Initial conditions problem fix

  # Don't filter first events: instead extract their Hb values to a separate vector
  # Also separate age, warm season and year

  # Remove donors that have only one event
  df <- df %>%
    droplevels() %>%
    group_by(donor) %>%
    filter(!n() == 1) %>%
    ungroup()

  first.events <- df %>%
    filter(first_event == TRUE)

  df <- df %>%
    filter(!is.na(Hb_first), !is.na(days_to_previous_fb),
           !is.na(previous_Hb), !is.na(Hb), first_event == FALSE,
           donat_phleb == 'K' | donat_phleb == '*' | donat_phleb == 'T',
           !is.na(previous_Hb_def)) %>%
    select(Hb, donor, days_to_previous_fb, age, previous_Hb_def, year, warm_season, Hb_first, consecutive_deferrals,
           recent_donations, recent_deferrals, previous_Hb, Hb_deferral, hour) %>%
    mutate(previous_Hb_def = as.integer(previous_Hb_def),
           warm_season = as.integer(warm_season), Hb_deferral = as.integer(Hb_deferral),
           original_Hb = Hb, days_to_previous_fb = log(days_to_previous_fb))

  # Calculate means here
  df2 <- df %>% mutate(donor = as.integer(as.factor(donor))) # otherwise colMeans complains about non-numeric columns
  par_means <- colMeans(df2)
  par_sds <- apply(df2, 2, sd)
  rm(df2)
  
  # Normalize the data
  if (normalize) {
    df <- normalize(df, columns = c("Hb","days_to_previous_fb", "age", "year", "Hb_first", "consecutive_deferrals",
                                    "recent_donations","recent_deferrals", "previous_Hb", "hour"))
  }

  test_train <- split_set(df, frac)
  common.train <- intersect(first.events$donor, test_train$train$donor)
  common.test <- intersect(first.events$donor, test_train$test$donor)
  first.train <- filter(first.events, donor %in% common.train)
  first.test <- filter(first.events, donor %in% common.test)

  test_train$train <- test_train$train %>%
    filter(donor %in% common.train) %>%
    mutate(donor = as.integer(as.factor(donor)))

  test_train$test <- test_train$test %>%
    filter(donor %in% common.test) %>%
    mutate(donor = as.integer(as.factor(donor)))

  train_dons <- test_train$train$donor
  test_dons <- test_train$test$donor

  # Z_train <- test_train$train %>%
  #   group_by(donor) %>%
  #   summarize(age_mean = mean(age), year_mean = mean(year), season_mean = mean(warm_season)) %>%
  #   select(age_mean, year_mean, season_mean)

  Z_train <- first.train %>%
    select(age, year, warm_season)

  Z_test <- first.test %>%
    select(age, year, warm_season)

  # Z_test <- test_train$test %>%
  #   group_by(donor) %>%
  #   summarize(age_mean = mean(age), year_mean = mean(year), season_mean = mean(warm_season)) %>%
  #   select(age_mean, year_mean, season_mean)

  Hb0_train <- select(first.train, Hb)
  Hb0_test <- select(first.test, Hb)

  if (normalize) {
    Hb0_train <- normalize(Hb0_train, columns = c("Hb"))
    Hb0_test <- normalize(Hb0_test, columns = c("Hb"))
    Z_train <- normalize(Z_train, columns = c("age", "year", "warm_season"))
    Z_test <- normalize(Z_test, columns = c("age", "year", "warm_season"))
  }

  y_train <- test_train$train$Hb
  y_test <- test_train$test$Hb
  original_Hb <- test_train$test$original_Hb
  full_Hb <- c(test_train$train$original_Hb, test_train$test$original_Hb)

  train_labels <- test_train$train$Hb_deferral
  test_labels <- test_train$test$Hb_deferral

  x_train <- test_train$train %>% select(days_to_previous_fb, age, previous_Hb_def, year, warm_season, previous_Hb,
                                         consecutive_deferrals, recent_donations, recent_deferrals, hour)

  x_test <- test_train$test %>% select(days_to_previous_fb, age, previous_Hb_def, year, warm_season, previous_Hb,
                                       consecutive_deferrals, recent_donations, recent_deferrals, hour)

  return(list(train_dons = train_dons,
              test_dons = test_dons,
              x_train = x_train,
              x_test = x_test,
              y_train = y_train,
              y_test = y_test,
              Z_train = Z_train,
              Z_test = Z_test,
              Hb0_train = Hb0_train,
              Hb0_test = Hb0_test,
              train_labels = train_labels,
              test_labels = test_labels,
              original_Hb = original_Hb,
              par_means = par_means,
              par_sds = par_sds))
}



stan_preprocess_le <- function(df, frac = NULL, normalize = TRUE, hlen = NULL, save_orig = FALSE) {
  # Function that makes the data ready for stan-analysis
  # This means getting rid of NA-values (meaning mostly first events),
  # normalizing the data and splitting it to test and train sets.
  # The le-version will have the last events as test-samples and other events as
  # train samples. This means that test-set will be length Ndon and train set larger.

  # Hlen variable can be used to select donors based on their donation history length
  # For negative values: select donors with less or equal than -hlen donations
  # For positive values: select donors with more or equal than hlen donations
  # e.g., hlen = 5, keep donors with 5 or more events
  # e.g., hlen = -10, keep donors with 10 or less events
  # Take into account that the last event is used for prediction and the first event is dropped

  # Remove donors that have only one event
  df <- df %>%
    droplevels() %>%
    group_by(donor) %>%
    filter(n() > 1) %>%
    ungroup()

  df <- df %>%
    filter(!is.na(Hb_first), !is.na(days_to_previous_fb),
           !is.na(Hb), !is.na(previous_Hb), first_event == FALSE,
           donat_phleb == 'K' | donat_phleb == '*' | donat_phleb == 'T',
           !is.na(previous_Hb_def)) %>%
    select(Hb, donor, days_to_previous_fb, age, previous_Hb_def, year, warm_season, Hb_first, consecutive_deferrals,
           recent_donations, recent_deferrals, previous_Hb, Hb_deferral, hour) %>%
    mutate(previous_Hb_def = as.integer(previous_Hb_def),
           warm_season = as.integer(warm_season), Hb_deferral = as.integer(Hb_deferral),
           original_Hb = Hb, days_to_previous_fb = log(days_to_previous_fb))

  df <- filter_based_on_number_of_donations(df, hlen)

  df <- df %>%
    droplevels() %>%
    group_by(donor) %>%
    filter(n() > 1) %>%
    ungroup()

  # Make donor_id - donor table
  donor_ids <- df %>%
    select(donor) %>%
    unique() %>%
    mutate(donor_id = as.integer(as.factor(donor)))

  df <- df %>%
    mutate(donor = as.integer(as.factor(donor)))

  # Calculate means here
  par_means <- colMeans(df)
  par_sds <- apply(df, 2, sd)

  if (save_orig == TRUE) {
    original <- df
  }

  # Normalize the data
  if (normalize) {
    df <- normalize(df, columns = c("Hb","days_to_previous_fb", "age", "year", "Hb_first", "consecutive_deferrals",
                                    "recent_donations","recent_deferrals", "previous_Hb","year","hour"))
  }

  # By default take the last events as test set
  if (is.null(frac)){
  test_set <- df %>%
    group_by(donor) %>%
    slice(n()) %>%
    ungroup()

  train_set <- df %>%
    group_by(donor) %>%
    slice(-n()) %>%
    ungroup()
  if (save_orig == TRUE) {
    original <- original %>%
      group_by(donor) %>%
      slice(-n()) %>%
      ungroup()
    }
  }
  train_dons <- train_set$donor
  test_dons <- test_set$donor

  y_train <- train_set$Hb
  y_test <- test_set$Hb
  original_Hb <- test_set$original_Hb

  train_labels <- train_set$Hb_deferral
  test_labels <- test_set$Hb_deferral

  # Remove previous Hb for state-dependence
  x_train <- train_set %>% select(days_to_previous_fb, age, previous_Hb_def, year, warm_season, Hb_first,
                                         consecutive_deferrals, recent_donations, recent_deferrals, hour)

  x_test <- test_set %>% select(days_to_previous_fb, age, previous_Hb_def, year, warm_season, Hb_first,
                                       consecutive_deferrals, recent_donations, recent_deferrals, hour)
  if (save_orig == TRUE) {
  original <- original %>% select(-Hb, -previous_Hb, -Hb_deferral)
  return(list(train_dons = train_dons,
              test_dons = test_dons,
              x_train = x_train,
              x_test = x_test,
              y_train = y_train,
              y_test = y_test,
              train_labels = train_labels,
              test_labels = test_labels,
              original_Hb = original_Hb,
              donor_ids = donor_ids,
              par_means = par_means,
              par_sds = par_sds,
              original = original))
  } else {
  return(list(train_dons = train_dons,
              test_dons = test_dons,
              x_train = x_train,
              x_test = x_test,
              y_train = y_train,
              y_test = y_test,
              train_labels = train_labels,
              test_labels = test_labels,
              original_Hb = original_Hb,
              donor_ids = donor_ids,
              par_means = par_means,
              par_sds = par_sds))
  }
}

stan_preprocess_icp_le <- function(df, frac = NULL, normalize = TRUE, hlen = NULL) {
  # Does mostly same thing as normal stan-preprocessing function.
  # Main exception is that this returns first Hb-values so that first events can be used
  # with Initial conditions problem fix

  # Don't filter first events: instead extract their Hb values to a separate vector
  # Also separate age, warm season and year

  # Hlen variable can be used to select donors based on their donation history length
  # For negative values: select donors with less or equal than -hlen donations
  # For positive values: select donors with more or equal than hlen donations
  # e.g., hlen = 5, keep donors with 5 or more events
  # e.g., hlen = -10, keep donors with 10 or less events
  # Take into account that the last event is used for prediction and the first event is dropped

  # Remove donors that have only one event
  df <- df %>%
    droplevels() %>%
    group_by(donor) %>%
    filter(!n() == 1) %>%
    ungroup()

  mean_Hb <- mean(df$Hb)
  sd_Hb <- sd(df$Hb)

  first.events <- df %>%
    filter(first_event == TRUE)

  def_df <- df %>%
    filter(donat_phleb == '*') %>%
    select(donor, dateonly)

  df <- df %>%
    filter(!is.na(Hb_first), !is.na(days_to_previous_fb),
           !is.na(previous_Hb), !is.na(Hb),
           donat_phleb == 'K' | donat_phleb == '*' | donat_phleb == 'T',
           !is.na(previous_Hb_def), first_event == FALSE) %>%
    select(Hb, donor, days_to_previous_fb, age, previous_Hb_def, year, warm_season, Hb_first, consecutive_deferrals,
           recent_donations, recent_deferrals, previous_Hb, Hb_deferral, hour, dateonly, don_id) %>%
    mutate(previous_Hb_def = as.integer(previous_Hb_def),
           warm_season = as.integer(warm_season), Hb_deferral = as.integer(Hb_deferral),
           original_Hb = Hb, days_to_previous_fb = log(days_to_previous_fb))

  # Subtract one from the hlen values due to discarding first event at this point
  df <- filter_based_on_number_of_donations(df, hlen)

  df <- df %>%
    droplevels() %>%
    group_by(donor) %>%
    filter(n() > 1) %>%
    ungroup()

  # Calculate means here
  par_means <- colMeans(df %>% select(-donor, -dateonly, -don_id))
  par_sds <- apply(df %>% select(-donor, -dateonly, -don_id), 2, sd)

  # Normalize the data
  if (normalize) {
    df <- normalize(df, columns = c("Hb","days_to_previous_fb", "age", "year", "Hb_first", "consecutive_deferrals",
                                    "recent_donations","recent_deferrals", "previous_Hb", "hour"))
  }

  if (is.null(frac)){
    test_set <- df %>%
      group_by(donor) %>%
      slice(n()) %>%
      ungroup()

    train_set <- df %>%
      group_by(donor) %>%
      slice(-n()) %>%
      ungroup()
  }

  donors <- intersect(train_set$donor, test_set$donor)
  donors <- intersect(donors, first.events$donor)

  # Make donor_id - donor table
  donor_ids <- tibble(donors) %>%
    unique() %>%
    mutate(donor = donors, donor_id = as.integer(as.factor(donors))) %>%
    select(-donors)

  train_set <- train_set %>%
    filter(donor %in% donors) %>%
    mutate(donor = as.integer(as.factor(donor)))

  test_set <- test_set %>%
    filter(donor %in% donors) %>%
    mutate(donor = as.integer(as.factor(donor)))

  first.events <- first.events %>%
    filter(donor %in% donors)

  train_dons <- train_set$donor
  test_dons <- test_set$donor

  Z <- first.events %>%
    select(age, year, warm_season, hour)

  Hb0 <- first.events %>%
    select(Hb)

  if (normalize) {
    Hb0 <- normalize(Hb0, columns = c("Hb"))
    Z <- normalize(Z, columns = c("age", "year", "hour"))
  }

  y_train <- train_set$Hb
  y_test <- test_set$Hb
  original_Hb <- test_set$original_Hb

  train_labels <- train_set$Hb_deferral
  test_labels <- test_set$Hb_deferral

  # Select dates
  train_dates <- train_set %>% select(donor, dateonly)
  test_dates <- test_set %>% select(donor, dateonly)

  train_events <- train_set %>% select(don_id)

  x_train <- train_set %>% select(days_to_previous_fb, age, previous_Hb_def, year, warm_season, previous_Hb,
                                         consecutive_deferrals, recent_donations, recent_deferrals, hour)

  x_test <- test_set %>% select(days_to_previous_fb, age, previous_Hb_def, year, warm_season, previous_Hb,
                                       consecutive_deferrals, recent_donations, recent_deferrals, hour)

  return(list(train_dons = train_dons,
              test_dons = test_dons,
              x_train = x_train,
              x_test = x_test,
              y_train = y_train,
              y_test = y_test,
              Z = Z,
              Hb0 = Hb0,
              train_labels = train_labels,
              test_labels = test_labels,
              original_Hb = original_Hb,
              len = nrow(first.events),
              donor_ids = donor_ids,
              par_means = par_means,
              par_sds = par_sds,
              train_dates = train_dates,
              test_dates = test_dates,
              train_events = train_events))
}


qr_decomposition <- function(df) {
  # Makes qr-decomposition on a given train data set
  # This makes the stan-analysis faster compared to using raw train data.
  qr0 <- qr(df)
  Q <- qr.Q(qr0)
  R <- qr.R(qr0)
  Q_star <- Q * sqrt(nrow(df) - 1)
  R_star <- R / sqrt(nrow(df) - 1)
  R_star_inv <- solve(R_star, tol = 1e-17)
  return(list(Q_star = Q_star, R_star = R_star, R_star_inv= R_star_inv))
}

plot_confusion_matrix <- function(table, title = NULL) {
  observed <- factor(c("Accepted", "Accepted", "Deferred", "Deferred"))
  predicted <- factor(c("Accepted", "Deferred", "Accepted", "Deferred"))
  Y <- as.numeric(table)
  df <- data.frame(predicted, observed, Y)

  conf.plot <- ggplot(data =  df, mapping = aes(x = observed, y = predicted)) +
    geom_tile(aes(fill = Y), colour = "white") +
    geom_text(aes(label = sprintf("%1.0f", Y)), vjust = 1, size = 7
              ) +
    scale_fill_gradient(low = "white", high = "gray") +
    theme_bw() + theme(legend.position = "none") +
    labs(x = "Observed", y = "Predicted")
  if (!is.null(title)) {
    conf.plot <- conf.plot + ggtitle(title)
  }
  return(conf.plot)
}


# Test functions / Alternative functions for preprocessing

hours_to_numeric <- function(date.obj) {
  h <- hour(date.obj)
  m <- minute(date.obj) * (1/60)
  time <- h + m
  return(time)
}

get_nb_deferrals_2y_per_date <- function(current_date, donor_data) {
  donor_data %>%
    filter(date < current_date & date > current_date %m-% years(x = 2)) %>%
    nrow()
}

get_nb_deferrals_2y_per_donor <- function(donor_data) {
  data.frame(recent_deferrals = donor_data$date %>%
               map_dbl( get_nb_deferrals_2y_per_date, donor_data %>% filter(Hb_deferral == 1)),
             date = donor_data$date)
}

get_recent_hb_deferrals <- function(df) {

  num_cores = availableCores() - 1
  plan(multiprocess, workers = num_cores)

  # https://stackoverflow.com/questions/40536067/how-to-adjust-future-global-maxsize-in-r
  options(future.globals.maxSize= 10485760000)

  df <- df %>%
    mutate(date = as_date(dateonly)) %>%
    group_by(donor) %>%
    nest() %>%
    mutate(recent_deferrals = future_map(data, get_nb_deferrals_2y_per_donor)) %>%
    unnest()
  return(df)
}


get_difference_donation <-function(donationID_int, all_data)
{
  donation_date <- all_data %>% filter(don_id == donationID_int) %>% .$date

  if(nrow(all_data %>% filter(date < donation_date &
                              (donat_phleb == 'K' & status == "-" |
                               donat_phleb == 'K' & status != "-" & dunno3 > 100 |
                               donat_phleb == 'H' & dunno3 > 100))) > 0 ) {
    test <- all_data %>%
      filter(date < donation_date) %>%
      filter(donat_phleb == 'K' & status == "-" |
               donat_phleb == 'K' & status != "-" & dunno3 > 100 |
               donat_phleb == 'H' & dunno3 > 100) %>%
      summarise(previous_date = max(date))
    days_to_previous_fb = as.numeric(donation_date - test$previous_date)
  }
  else{
    days_to_previous_fb = NA
  }
  return(days_to_previous_fb)
}

get_difference_donor <- function(all_data_single_donor){
  donationIDs <- all_data_single_donor$don_id

  output <- enframe(sapply(donationIDs, get_difference_donation, all_data = all_data_single_donor)) %>%
    mutate(don_id = donationIDs) %>%
    rename(days_to_previous_fb = value)

  return(output)
}

add_days_to_prev_fb <- function(df) {
  library(furrr)
  num_cores = availableCores() - 1
  plan(multiprocess, workers = num_cores)

  df <- mutate(df, date = as_date(dateonly))
  df$don_id <- as.character(seq.int(1:nrow(df)))

  #df <- df %>% droplevels()

  dtp_df <- df %>%
    droplevels() %>%
    split(.$donor) %>%
    future_map_dfr(~ get_difference_donor(.))

  df <- df %>%
    full_join(dtp_df, by = "don_id") %>%
    mutate(days_to_previous_fb = round(days_to_previous_fb)) %>%
    select(don_id, donor, days_to_previous_fb)

  return(df)
}

read_predictions <- function(fname) {
  df <- read.csv(fname,
                 sep = ",",
                 stringsAsFactors = FALSE,
                 header = TRUE,
                 comment.char = '#')

  means <- df[grepl("$1", names(df))]
  quantiles <- df[grepl("$2", names(df))]

  mcol <- as.numeric(means[1,])
  qcol <- as.numeric(quantiles[1,])

  out.df <- cbind(pred_means = mcol, lower_quantiles = qcol)
  return(out.df)
}

pairs_stan <- function(chain, stan_model, pars) {
  # From https://discourse.mc-stan.org/t/how-can-i-solve-bfmi-low-problem/3018/
  energy <- as.matrix(sapply(get_sampler_params(stan_model, inc_warmup = F),
                             function(x) x[,"energy__"]))
  pars <- extract(stan_model, pars = pars, permuted = F)
  df <- data.frame(energy[,chain], pars[,chain,])
  names(df)[1] <- "energy"
  GGally::ggpairs(df, title = paste0("Chain", chain),
                  lower = list(continuous = GGally::wrap("points", alpha = 0.2)))
}

# Helper function for creating stan-lists:
create_stan_list <- function(df, slopevar = NULL, icpfix = FALSE, rdump = FALSE, filename = NULL, threshold = NULL, dumpdir = NULL) {
  # Takes output of stan_preprocess or stan_preprocess_icp as input

  # Create the list without slope
  if (is.null(slopevar)) {
    x_train <- df$x_train
    y_train <- df$y_train
    x_test <- unname(as.matrix(df$x_test))
    y_test <- df$y_test
    train_dons <- df$train_dons
    test_dons <- df$test_dons
  } else {
    # Create the list with given slope variable
    x_train <- df$x_train
    slope_train <- pull(x_train, slopevar)
    x_train <- select(x_train, -slopevar)

    y_train <- df$y_train

    x_test <- df$x_test
    slope_test <- pull(x_test, slopevar)
    x_test <- select(x_test, -slopevar)
    x_test <- unname(as.matrix(x_test))

    y_test <- df$y_test
    train_dons <- df$train_dons
    test_dons <- df$test_dons
  }

  # All models use QR-reparametrizarion so it will be done here
  qr0 <- qr_decomposition(x_train)

  if (icpfix == FALSE) {
    stanlist <- list(N = nrow(x_train),
                     K = ncol(x_train),
                     Ndon = length(unique(train_dons)),
                     Q_star = qr0$Q_star,
                     R_star = qr0$R_star,
                     R_star_inv = qr0$R_star_inv,
                     Hb = y_train,
                     donor = train_dons,
                     Ntest = nrow(x_test),
                     #Ntest_don = length(unique(test_dons)),
                     x_test = x_test,
                     test_donor = test_dons)
  } else {
    Z <- df$Z
    Hb0 <- df$Hb0
    stanlist <- list(N = nrow(x_train),
                     K = ncol(x_train),
                     Ndon = length(unique(train_dons)),
                     L = ncol(Z),
                     Q_star = qr0$Q_star,
                     R_star = qr0$R_star,
                     R_star_inv = qr0$R_star_inv,
                     Hb = y_train,
                     donor = train_dons,
                     Z = Z,
                     Hb_0 = unname(as.numeric(unlist(Hb0))),
                     Ntest = nrow(x_test),
                     #Ntest_don = length(unique(test_dons)),
                     x_test = x_test,
                     test_donor = test_dons)
  }
  # Check if slope variable has to be added to the list
  if (!is.null(slopevar)) {
    stanlist$x1 <- slope_train
    stanlist$x_1_test <- slope_test
    stanlist$x_2_test <- x_test
    stanlist$x_test <- NULL
  }

  if (rdump == FALSE) {return(stanlist)}
  else {
    N = nrow(x_train)
    K = ncol(x_train)
    Ndon = length(unique(train_dons))
    Q_star = qr0$Q_star
    R_star = qr0$R_star
    R_star_inv = qr0$R_star_inv
    Hb = y_train
    donor = train_dons
    Ntest = nrow(x_test)
    #Ntest_don = length(unique(test_dons))
    x_test = x_test
    test_donor = test_dons
    threshold = threshold
    if (icpfix == TRUE) {
      L = ncol(Z)
      Z = Z
      #Hb_0 = unname(as.numeric(unlist(Hb0_train)))
      Hb_0 = unname(as.numeric(unlist(Hb0)))
      #Z_test = Z_test
      #Hb_0_test = unname(as.numeric(unlist(Hb0_test)))
    }
    if (!is.null(slopevar)) {
      x1 <- slope_train
      x_1_test <- slope_test
      x_2_test <- x_test
    }
    if (icpfix == TRUE & !is.null(slopevar)) {
      stan_rdump(c("N", "K", "Ndon", "L", "x1", "Q_star", "R_star", "R_star_inv", "Hb", "donor", "Z", "Hb_0", "Ntest",
                   "x_1_test", "x_2_test", "test_donor", "threshold"),
                 file = paste(dumpdir,filename,".R", sep = ''))
    } else if (icpfix == TRUE) {
      stan_rdump(c("N", "K", "Ndon", "L", "Q_star", "R_star", "R_star_inv", "Hb", "donor", "Z", "Hb_0", "Ntest",
                   "x_test", "test_donor","threshold"),
                 file = paste(dumpdir,filename,".R", sep = ''))
    } else if (!is.null(slopevar)) {
      stan_rdump(c("N", "K", "Ndon", "x1", "Q_star", "R_star", "R_star_inv", "Hb", "donor", "Ntest",
                   "x_1_test", "x_2_test", "test_donor", "threshold"),
                 file = paste(dumpdir,filename,".R", sep = ''))
    } else {
      stan_rdump(c("N", "K", "Ndon","Q_star", "R_star", "R_star_inv", "Hb", "donor","Ntest",
                   "x_test", "test_donor", "threshold"),
                 file = paste(dumpdir,filename,".R", sep = ''))
    }
  }
}


prediction_results <- function(act, pred, act_labels, pred_labels, male = TRUE, Hb_cutoff_male = 135, Hb_cutoff_female = 125) {

    comp_df <- as.data.frame(cbind(prediction = pred, actual = act, deferral = act_labels))
    comp_df$deferral <- as.factor(comp_df$deferral)

    xymin <- min(min(comp_df$prediction),min(comp_df$actual))
    xymax <- max(max(comp_df$prediction),max(comp_df$actual))

    comp_plot <- ggplot(comp_df, aes(x = prediction, y=actual, color = deferral)) +
      geom_point() +
      xlim(xymin,xymax) + ylim(xymin,xymax) +
      geom_abline(intercept = 0, slope = 1)

    if (male == TRUE) {
      comp_plot <- comp_plot + geom_vline(xintercept = Hb_cutoff_male, linetype = "dashed") +
        ggtitle("Predicted vs Actual Hb-values, male donors") +
        geom_hline(yintercept = Hb_cutoff_male, linetype = "dashed")

    } else {
      comp_plot <- comp_plot + geom_vline(xintercept = Hb_cutoff_female, linetype = "dashed") +
        ggtitle("Predicted vs Actual Hb-values, female donors") +
        geom_hline(yintercept = Hb_cutoff_female, linetype = "dashed")
    }

    conf.matrix <- caret::confusionMatrix(as.factor(pred_labels), as.factor(act_labels))
    cm.plot <- plot_confusion_matrix(conf.matrix$table)

    mae <- mae(act, pred)
    rmse <- rmse(act, pred)

    return(list(conf.matrix = conf.matrix,
                mae = mae,
                rmse = rmse,
                cm.plot = cm.plot,
                comp_plot = comp_plot))
}

plot_param_cis <- function(df, params = NULL) {
  if (!is.null(params)) {
    colnames(df) <- params
  }
  ggplot(data = melt(df), aes(x=variable, y=value))+
    geom_boxplot(aes(fill = variable)) + geom_hline(yintercept = 0) + coord_flip()
}

# Variables to lag are for instance: c("Eryt", "HKR", "Leuk", "Trom", "MCH", "MCHC", "MCV", "RDW", "CRP", "Ferritin", "TransferrinR")
# If test_data is TRUE, then the last donations are used as the test data set, otherwise all donations are used as the train set
# and the test data is given separately (out-of-sample prediction).
stan_preprocess_new <- function(df, normalize = TRUE, Hb_index = 1, tolag = NULL, basic_variables = NULL,
                                donor_variables = NULL, test_data = TRUE, hlen = NULL, hlen_exactly = FALSE) {
  message("In stan_preprocess_new function")
  
  #hlen_orig <- hlen
  # Preprocessing for combined dataset
  # tolag variable defines which variables should be lagged
  # (whether we should use previous or "current" measurements)
  # donor_variables: Character vector of variables that should be grouped for each donor
  # output in a separate data frame
  
  #message(sprintf("Number of donors (1) is %i", ndonor(df)))
  old_count <- nrow(df); old_count2 <- ndonor(df)
  df <- df %>% filter(first_event == FALSE)    # Drop the first donation events
  message(sprintf("Dropped %i / %i donations (%i / %i donors) because dropping those donations with first_event==TRUE\n", 
              old_count - nrow(df), old_count, old_count2 - ndonor(df), old_count2))
  
  #message(sprintf("Number of donors (2) is %i", ndonor(df)))                      
  df2 <- df %>% filter(is.na(Hb_first) | is.na(days_to_previous_fb) |
                      is.na(Hb) | first_event == TRUE |
                      #!(donat_phleb == 'K' | donat_phleb == '*') |
                      is.na(previous_Hb_def))
  stopifnot(nrow(df2) == 0)
  
  #message(sprintf("Number of donors (3) is %i", ndonor(df)))
  old_count <- nrow(df); old_count2 <- ndonor(df)
  # Filter donors with 1 or <= 2 events
  if (!is.null(tolag)) {
    limit <- 1 + ifelse(test_data, 1, 0) # Note that we already dropped the donations with first_event == TRUE
    df <- df %>%
      droplevels() %>%
      group_by(donor) %>%
      filter(n() >= limit) %>% 
      ungroup()
    df <- df  %>% 
      group_by(donor) %>% 
      arrange(dateonly) %>% 
      mutate_at(tolag, lag) %>% 
      ungroup()
  } else {
    limit <- 1 + ifelse(test_data, 1, 0) # Note that we already dropped the donations with first_event == TRUE
    df <- df %>%
      group_by(donor) %>%
      filter(n() >= limit) %>%   
      ungroup()
  }
  message(sprintf("Dropped %i / %i donations (%i / %i donors) because dropping those donors with only at most two donations (or at most 3 donations if we have lagged variables.\n", 
                  old_count - nrow(df), old_count, old_count2 - ndonor(df), old_count2))

  message(sprintf("Number of donors (4) is %i", ndonor(df)))
  
  # old_count <- nrow(df); old_count2 <- ndonor(df)
  # if (!is.null(hlen) && hlen != 0) {
  #   hlen <- ifelse(hlen > 0, hlen - 1, hlen + 1)      # Because we already dropped the first event
  # }
  # df <- filter_based_on_number_of_donations(df, hlen, hlen_exactly)
  # message(sprintf("Dropped %i / %i donations (%i / %i donors) because we use time series with length at least %i.\n", 
  #                 old_count - nrow(df), old_count, old_count2 - ndonor(df), old_count2, hlen_orig))
  
  #message(sprintf("Number of donors (5) is %i", ndonor(df)))
  # Change donor into integer
  df <- df  %>% 
    mutate(donor = as.factor(donor)) %>%
    droplevels() %>% 
    mutate(donor = as.integer(donor)) %>% 
    arrange(donor, dateonly)
  #message(sprintf("Number of donors (6) is %i", ndonor(df)))
  if (!is.null(donor_variables)) {
    C <- df %>%
      select(donor, all_of(donor_variables)) %>% 
      distinct()
    df <- df %>% 
      select(-all_of(donor_variables))
  } else {
    C = NULL
  }
  
  # Split to test set for which the last event is chosen and train set where are the rest
  if (test_data) {
    test_set <- df %>% 
      group_by(donor) %>%
      slice(n()) %>% 
      ungroup()
    train_set <- df %>%
      group_by(donor) %>%
      slice(-n()) %>%
      ungroup()
  } else {
    train_set <- df
  }
  #message(sprintf("Number of donors (7) is %i", ndonor(df)))
  # Get the mean and sd parameters used for standardization from train data:
  # https://stats.stackexchange.com/questions/174823/how-to-apply-standardization-normalization-to-train-and-testset-if-prediction-i
  par_means <- colMeans(train_set[which(check_numeric(train_set))])
  par_sds <- apply(train_set[which(check_numeric(train_set))], 2, sd)
  
  train_donors <- train_set %>% 
    pull(donor)
  train_set <- train_set %>% 
    select(-donor)
  if (test_data) {
    test_donors <- test_set %>% 
      pull(donor)
    test_set <- test_set %>% 
      select(-donor)
    y_test <- test_set %>% 
      pull(Hb_index)
    x_test <- test_set %>% 
      select(-all_of(Hb_index))
  }
  
  y_train <- train_set %>% 
    pull(Hb_index)
  x_train <- train_set %>% 
    select(-all_of(Hb_index))
  
  # Normalize all non-binary yet numeric variables
  if (normalize) {
    x_train <- normalize(x_train, which(check_numeric(x_train)))
    #y_train <- (y_train - mean(y_train)) / sd(y_train)
    y_train <- normalize_vector(y_train)
    if (test_data) {
      x_test_norm <- normalize_with_params(x_test[,which(check_numeric(x_test))], means = par_means[-Hb_index], sds = par_sds[-Hb_index])
      x_test <- x_test_norm %>% bind_cols(x_test %>% select(-c(which(check_numeric(x_test)))))
      x_test <- x_test %>% select(colnames(x_train))
      #y_test <- (y_test - par_means[Hb_index]) / par_sds[Hb_index]
      y_test <- normalize_vector(y_test, par_means[[Hb_index]], par_sds[[Hb_index]])
    }
    if (!is.null(donor_variables)) {
      C.norm <- normalize(C %>% select(-donor), which(check_numeric(C %>% select(-donor))))
      C <- C.norm %>% add_column(donor = C$donor)
    }
  }
  
  if (!is.null(donor_variables)) {
    # Make sure the data is in same order as train_donors and test_donors
    # and remove donor variable
    C <- C %>% arrange(donor) %>% select(-donor)
  }
  
  message(sprintf("Basic variables are %s\n", paste(basic_variables, collapse=" ")))
  message(sprintf("Variables in x_train are %s\n", paste(colnames(x_train), collapse=" ")))
  
  # Filter unwanted variables
  #x_train <- x_train %>% select(-matches("first_event|Hb_deferral|donat_phleb|dateonly"))
  tryCatch(
    error = function(cnd){
      message(sprintf("Basic variables are %s\n", paste(basic_variables, collapse=" ")))
    },
    {
      x_train <- x_train %>% select(all_of(basic_variables))
    }
  )
  
  if (test_data) {
    #x_test <- x_test %>% select(-matches("first_event|Hb_deferral|donat_phleb|dateonly"))
    x_test <- x_test %>% select(all_of(basic_variables))
  } else {
    x_test = NULL
    y_test = NULL
    test_donors = NULL
  }
  
  return(list(x_train = x_train,
              y_train = y_train,
              x_test = x_test,
              y_test = y_test,
              train_donors = train_donors,
              test_donors = test_donors,
              par_means = par_means,
              par_sds = par_sds,
              C = C))
}



check_numeric <- function(df) {
  #bins <- apply(df,2,function(x) { all(x %in% 0:1) })
  nums <- unlist(lapply(df, is.numeric))
  #nums <- nums == !bins
  return(nums)
}



first_measurements <- function(df, means, sds, hlen = 2, normalize = TRUE) {
  # DF must have desired variables, a first_event flag and donor identifier
  
  # Similar preprocessing as in stan_list function
  df <- df %>%
    droplevels() %>%
    group_by(donor) %>%
    arrange(as.integer(donor)) %>% 
    filter(!n() <= hlen) %>%
    ungroup()
  
  df <- df %>% 
    filter(first_event == TRUE)
  
  if (normalize & !is.null(names(means))) {
    # Select only parameters which have a mean value in the vector
    # in case of a named vector
    norm.df <- normalize_with_params(df[,names(means)], means, sds)
    #norm.df <- normalize(df[,names(means)], names(means))
    df <- norm.df %>% bind_cols(df %>% select(-c(names(means))))
  }
  Hb_0 <- df %>% pull(Hb)
  df <- df %>% select(-first_event, -Hb) 
  return(list(Z = df,
              Hb_0 = Hb_0))
}

sl_to_stan_m1 <- function(sl, icp = FALSE, Z = NULL) {
  qr <- qr_decomposition(sl$x_train)
  data <- list(N = nrow(sl$x_train),
               K = ncol(sl$x_train),
               Ndon = length(unique(sl$train_donors)),
               Q_star = qr$Q_star,
               R_star = qr$R_star,
               R_star_inv = qr$R_star_inv,
               Hb = sl$y_train,
               donor = sl$train_donors,
               Ntest = nrow(sl$x_test),
               x_test = sl$x_test,
               test_donor = sl$test_donors)
  if (icp) {
    data[["Z"]] <- Z$Z
    data[["Hb_0"]] <- Z$Hb_0
    data[["L"]] <- ncol(Z$Z)
  }
  return(data)
}


stan_preprocess_deltamodel <- function(df, normalize = TRUE, Hb_index = 1, tolag = NULL, mutate_don = TRUE,
                                       donor_variables = NULL) {
  # Preprocessing for combined dataset
  # tolag variable defines which variables should be lagged
  # (whether we should use previous or "current" measurements)
  
  if (!is.null(tolag)) {
    df <- df %>%
      droplevels() %>%
      group_by(donor) %>%
      arrange(dateonly) %>% 
      filter(n() > 2) %>%
      ungroup() %>% 
      mutate_at(tolag, lag) %>% 
      drop_na()
  } else {
    df <- df %>%
      droplevels() %>%
      group_by(donor) %>%
      filter(!n() == 1) %>%
      ungroup()
  }
  
  if (mutate_don) {
    donor_ids <- unique(pull(df, donor))
    df <- df %>% 
      mutate(donor = as.integer(as.factor(donor))) %>%
      droplevels()
    df <- df %>% arrange(donor)
  }
  
  if (!is.null(donor_variables)) {
    C <- df %>%
      select(donor, donor_variables) %>% 
      distinct()
    df <- df %>% 
      select(-donor_variables)
  } else {
    C = NULL
  }
  
  # Split to test set for which the last event is chosen and train set where are the rest
  test_set <- df %>% 
    group_by(donor) %>%
    slice(n()) %>% 
    ungroup()
  train_set <- df %>%
    group_by(donor) %>%
    slice(-n()) %>%
    ungroup()
  
  # Get the mean and sd parameters used for standardization from train data:
  # https://stats.stackexchange.com/questions/174823/how-to-apply-standardization-normalization-to-train-and-testset-if-prediction-i
  par_means <- colMeans(train_set[which(check_numeric(train_set))])
  par_sds <- apply(train_set[which(check_numeric(train_set))], 2, sd)
  
  #train_set <- train_set %>% 
  #  mutate(donor = as.integer(donor))
  #test_set <- test_set %>% 
  #  mutate(donor = as.integer(donor))  
  
  train_donors <- train_set %>% 
    pull(donor)
  train_set <- train_set %>% 
    select(-donor)
  test_donors <- test_set %>% 
    pull(donor)
  test_set <- test_set %>% 
    select(-donor)
  
  y_test <- test_set %>% 
    pull(Hb_index)
  x_test <- test_set %>% 
    select(-Hb_index)
  
  y_train <- train_set %>% 
    pull(Hb_index)
  x_train <- train_set %>% 
    select(-Hb_index)
  
  first_events <- which(ifelse(train_donors != lag(train_donors, default = 0), TRUE, FALSE))
  
  # Normalize all non-binary yet numeric variables
  if (normalize) {
    x_train <- normalize(x_train, which(check_numeric(x_train)))
    x_test_norm <- normalize_with_params(x_test[,which(check_numeric(x_test))], means = par_means[-Hb_index], sds = par_sds[-Hb_index])
    x_test <- x_test_norm %>% bind_cols(x_test %>% select(-c(which(check_numeric(x_test)))))
    x_test <- x_test %>% select(colnames(x_train))
    Hb_m <- mean(y_train)
    Hb_sd <- sd(y_train) 
    y_train <- (y_train - mean(y_train)) / sd(y_train)
    y_test <- (y_test - Hb_m) / Hb_sd
    if (!is.null(donor_variables)) {
      C.norm <- normalize(C %>% select(-donor), which(check_numeric(C %>% select(-donor))))
      C <- C.norm %>% add_column(donor = C$donor)
    }
  }
  
  if (!is.null(donor_variables)) {
    # Make sure the data is in same order as train_donors and test_donors
    # and remove donor variable
    C <- C %>% arrange(donor) %>% select(-donor)
  }
  
  Hb_lag <- x_train %>% pull(previous_Hb)
  x_train <- x_train %>% select(-previous_Hb)
  
  Hb_lag_test <- x_test %>% pull(previous_Hb)
  x_test <- x_test %>% select(-previous_Hb)
  
  return(list(x_train = x_train,
              y_train = y_train,
              x_test = x_test,
              y_test = y_test,
              train_donors = train_donors,
              test_donors = test_donors,
              par_means = par_means,
              par_sds = par_sds,
              first_events = first_events,
              Hb_lag = Hb_lag,
              Hb_lag_test = Hb_lag_test,
              C = C))
}  

# Variables to lag are for instance: c("Eryt", "HKR", "Leuk", "Trom", "MCH", "MCHC", "MCV", "RDW", "CRP", "Ferritin", "TransferrinR")
# If test_data is TRUE, then the last donations are used as the test data set, otherwise all donations are used as the train set
# and the test data is given separately (out-of-sample prediction).
stan_preprocess_icp_new <- function(df, Hb_index = 1, frac = NULL, normalize = TRUE, hlen = NULL, hlen_exactly=FALSE,
                                    tolag = NULL, basic_variables, donor_variables = NULL, test_data = TRUE) {
  message("In stan_preprocess_icp_new function")
  # Does mostly same thing as normal stan-preprocessing function.
  # Main exception is that this returns first Hb-values so that first events can be used
  # with Initial conditions problem fix
  
  # Don't filter first events: instead extract their Hb values to a separate vector
  # Also separate age, warm season and year
  
  #message(sprintf("Number of icp-donors (1) is %i", ndonor(df)))
  old_count <- nrow(df); old_count2 <- ndonor(df)
  if (!is.null(tolag)) {
    limit <- 2 + ifelse(test_data, 1, 0)
    df <- df %>%
      droplevels() %>%
      group_by(donor) %>%
      filter(n() >= limit) %>% 
      arrange(dateonly) %>% 
      mutate_at(tolag, lag) %>%
      ungroup() #%>% 
      #drop_na()
  } else {
    limit <- 2 + ifelse(test_data, 1, 0)
    df <- df %>%
      droplevels() %>%
      group_by(donor) %>%
      filter(n() >= limit) %>%
      ungroup()
  }
  message(sprintf("Dropped %i / %i donations (%i / %i donors) because we dropped time series with length at most 1\n", 
                  old_count - nrow(df), old_count, old_count2 - ndonor(df), old_count2))
  #message(sprintf("Number of icp-donors (2) is %i", ndonor(df)))
  
  # old_count <- nrow(df); old_count2 <- ndonor(df)
  # df <- filter_based_on_number_of_donations(df, hlen, hlen_exactly)
  # message(sprintf("Dropped %i / %i donations (%i / %i donors) because we are using time series with length at least %s\n", 
  #                 old_count - nrow(df), old_count, old_count2 - ndonor(df), old_count2, hlen))
  #message(sprintf("Number of icp-donors (3) is %i", ndonor(df)))
  
  # Change donor into integer
  df <- df  %>% 
    mutate(donor = as.factor(donor)) %>%
    droplevels() %>% 
    mutate(donor = as.integer(donor)) %>% 
    arrange(donor, dateonly)
  #message(sprintf("Number of icp-donors (4) is %i", ndonor(df)))
  if (!is.null(donor_variables)) {
    C <- df %>%
      select(donor, all_of(donor_variables)) %>% 
      distinct()
    df <- df %>% 
      select(-all_of(donor_variables))
  } else {
    C = NULL
  }
  #message(sprintf("Number of icp-donors (5) is %i", ndonor(df)))
  
  #df <- df %>% 
  #  mutate(donor = as.factor(donor)) %>%
  #  droplevels()
  
  if (test_data) {
    test_set <- df %>% 
      group_by(donor) %>%
      slice(n()) %>% 
      ungroup()
    train_set <- df %>%
      group_by(donor) %>%
      slice(-n()) %>%
      ungroup()
  } else {
    train_set <- df
  }
  
  # Get the mean and sd parameters used for standardization from train data:
  # https://stats.stackexchange.com/questions/174823/how-to-apply-standardization-normalization-to-train-and-testset-if-prediction-i
  par_means <- colMeans(train_set[sapply(df, is.numeric)], na.rm = TRUE)
  par_sds <- apply(train_set[sapply(df, is.numeric)], 2, sd, na.rm = TRUE)
  
  #train_set <- train_set %>% 
  #  mutate(donor = as.integer(donor))
  
  #if (test_data) {
  #test_set <- test_set %>% 
  #  mutate(donor = as.integer(donor))  
  #}
  train_donors <- train_set %>% 
    pull(donor)
  train_set <- train_set %>% 
    select(-donor)
  
  if (test_data) {
    test_donors <- test_set %>% 
      pull(donor)
    test_set <- test_set %>% 
      select(-donor)
    
    y_test <- test_set %>% 
      pull(Hb_index)
    x_test <- test_set %>% 
      select(-all_of(Hb_index))
  }
  y_train <- train_set %>% 
    pull(Hb_index)
  x_train <- train_set %>% 
    select(-all_of(Hb_index))
  
  # Normalize all non-binary yet numeric variables
  if (normalize) {
    x_train <- normalize(x_train, which(check_numeric(x_train)))
    if (test_data) {
      x_test_norm <- normalize_with_params(x_test[,which(check_numeric(x_test))], means = par_means[-Hb_index], sds = par_sds[-Hb_index])
      x_test <- x_test_norm %>% bind_cols(x_test %>% select(-c(which(check_numeric(x_test)))))
      x_test <- x_test %>% select(colnames(x_train))
      #y_test <- (y_test - par_means[Hb_index]) / par_sds[Hb_index]
      y_test <- normalize_vector(y_test, par_means[[Hb_index]], par_sds[[Hb_index]])
    }
    #y_train <- (y_train - mean(y_train)) / sd(y_train)
    y_train <- normalize_vector(y_train)
    if (!is.null(donor_variables)) {
      C.norm <- normalize(C %>% select(-donor), which(check_numeric(C %>% select(-donor))))
      C <- C.norm %>% add_column(donor = C$donor)
    }
  }
  
  if (!is.null(donor_variables)) {
    # Make sure the data is in same order as train_donors and test_donors
    # and remove donor variable
    C <- C %>% arrange(donor) %>% select(-donor)
  }
  
  first_events <- which(ifelse(train_donors != lag(train_donors, default = 0), TRUE, FALSE))
  
  # These variables can be used to explain the first Hb value, they are not related to previous donations
  Z_variables <- c("age", "year", "warm_season", "hour")
  if ("sex" %in% colnames(x_train)) Z_variables <- c(Z_variables, "sex")
  Z <- x_train %>%
    filter(row_number() %in% first_events) %>% 
    select(all_of(Z_variables))

  # Convert NA values in days_to_previoys, previous_Hb_def and previous_Hb to 0
  # And select predictor variables
  vars_to_replace_na <- c("days_to_previous_fb", "previous_Hb_def", "previous_Hb")
  x_train <- x_train %>% 
    # mutate(days_to_previous_fb = ifelse(is.na(days_to_previous_fb), 0, days_to_previous_fb),
    #        previous_Hb_def = ifelse(is.na(previous_Hb_def), 0, previous_Hb_def),
    #        previous_Hb = ifelse(is.na(previous_Hb), 0, previous_Hb)) %>% 
    mutate_at(vars_to_replace_na, replace_na, 0) %>%
    mutate_at(tolag, replace_na, 0) %>% 
    select(all_of(basic_variables))
    #select(-matches("first_event|Hb_deferral|donat_phleb|dateonly"))
    #select(days_to_previous_fb, age, previous_Hb_def, year, warm_season, previous_Hb,
    #                            consecutive_deferrals, recent_donations, recent_deferrals, hour)
  if (test_data) {
  x_test <- x_test %>% 
    # mutate(days_to_previous_fb = ifelse(is.na(days_to_previous_fb), 0, days_to_previous_fb),
    #        previous_Hb_def = ifelse(is.na(previous_Hb_def), 0, previous_Hb_def),
    #        previous_Hb = ifelse(is.na(previous_Hb), 0, previous_Hb)) %>% 
    mutate_at(vars_to_replace_na, replace_na, 0) %>%
    mutate_at(tolag, replace_na, 0) %>% 
    select(all_of(basic_variables))
    #select(-matches("first_event|Hb_deferral|donat_phleb|dateonly"))
  } else {
    x_test = NULL
    y_test = NULL
    test_donors = NULL
  }
  
  return(list(train_donors = train_donors,
              test_donors = test_donors,
              x_train = x_train,
              x_test = x_test,
              y_train = y_train,
              y_test = y_test,
              Z = Z,
              par_means = par_means,
              par_sds = par_sds,
              first_events = first_events,
              C = C))
}

create_model_list <- function(fit, type, sl) {
  message("In create_model_list function")
  # Create_model_list function can be used to create model_list object to 
  # do out-of-sample predictions for new donors. This function takes as input:
  # Stan-fit object, type parameter which describes which kind of model was fit and 
  # stan-list object for _test_ set
  model.list <- list()
  model.list$beta <- get_params(pars = names(fit)[grepl("beta", names(fit))], fit = fit)
  model.list$beta <- as.matrix(model.list$beta %>% select(-contains("tilde")))
  model.list$x <- sl$x_train
  model.list$y <- sl$y_train
  model.list$donor <- sl$train_donors
  model.list$type <- type
  if (type == "dlmm") {
    model.list$sigma_b <- unlist(get_params(pars = c("sigma_b"), fit = fit))
    model.list$sigma_epsilon <- unlist(get_params(pars = c("sigma_eps"), fit = fit))
    model.list$ups <- as.matrix(get_params(pars = names(fit)[grepl("ups", names(fit))], fit = fit))
    model.list$sigma_eeta <- unlist(get_params(pars = c("sigma_eeta"), fit = fit))
    model.list$theta <- unlist(get_params(pars = c("theta"), fit = fit))
    model.list$Z <- as.matrix(sl$Z)
    model.list$first_events <- sl$first_events
  } else {
    model.list$sigma_b <- unlist(get_params(pars = c("sigmab"), fit = fit))
    model.list$sigma_epsilon <- unlist(get_params(pars = c("sigmaeps"), fit = fit))
  }
  if (!is.null(sl$C)) {
    model.list$phi <- as.matrix(get_params(pars = c("phi"), fit = fit))
    model.list$C <- as.matrix(sl$C)
  }
  return(model.list)
}


parameter_cis <- function(parameters, pnames = NULL, digits = 3) {
  cis <- apply(parameters, MARGIN = 2, MeanCI, conf.level = 0.95)
  #cis <- t(cis)[,c(2,1,3)]
  cis <- t(cis)
  if (!is.null(pnames)) rownames(cis) <- pnames
  return(round(cis, digits = digits))
}

model_results <- function(actual, predicted, probabilities, threshold, Hb_mean, Hb_sd, lims = NULL) {
  # This function will:
  # - Plot comparison
  # - Calculate errors
  #   . RMSE
  #   . MAE
  # - ROC-curve
  # - Cutpoint
  # - Confusion matrix with the cutpoint
  
  # *Inputs*:
  # Actual values, predicted values, threshold, Hb_mean and Hb_sd, also ROC-params
  
  result.df <- as.data.frame(cbind(actual = actual, predicted = predicted, fractions = probabilities))
  result.norm <- result.df  %>% mutate(actual = denormalize_vector(actual, Hb_mean, Hb_sd)) %>% 
    mutate(predicted = denormalize_vector(predicted, Hb_mean, Hb_sd))
  
  result.norm <- result.norm %>% mutate(deferral = as.factor(ifelse(actual < threshold, 1, 0)))
  
  xymin <- min(min(result.norm$predicted),min(result.norm$actual))
  xymax <- max(max(result.norm$predicted),max(result.norm$actual))
  
  comp_plot <- ggplot(result.norm, aes(x = actual, y=predicted, color = deferral)) +
    geom_point() +
    #xlim(xymin,xymax) + ylim(xymin,xymax) +
    scale_x_continuous(breaks = generate_my_breaks(20), limits=c(xymin,xymax)) +
    scale_y_continuous(breaks = generate_my_breaks(20), limits=c(xymin,xymax)) +
    geom_abline(intercept = 0, slope = 1) +
    labs(x = "observed", y = "predicted", colour = "status") +
    geom_vline(xintercept = threshold, linetype = "dashed") + geom_hline(yintercept = threshold, linetype = "dashed") +
    scale_colour_discrete(labels=c("accepted", "deferred"))
  
  if (!is.null(lims)) {comp_plot <- comp_plot + xlim(lims) + ylim(lims)}
  
  par(pty="s")
  roc_plot <- pROC::roc(data = result.norm, response = "deferral", predictor = "fractions", plot = TRUE, legacy.axes = TRUE, percent = TRUE,
                        xlab = "False Positive Percentage", ylab = "True Positive Percentage", ci = TRUE)
  
  # Find an optimal cutoff value
  # Now using sum_sens_spec metric which means we're trying to maximize sensitivity + specificity values
  # This will produce a lot of false positives, thiscould be better optimized by using another metric
  cp <- cutpointr(result.norm, fractions, deferral, method = maximize_metric, metric = sum_sens_spec)
  
  mae <- mae(result.norm$actual, result.norm$predicted)
  rmse <- rmse(actual = result.norm$actual, predicted = result.norm$predicted)
  
  original_Hb2 <- to_mmol_per_litre(result.norm$actual)
  Hb_predictions2 <- to_mmol_per_litre(result.norm$predicted)
  mae2  <- mae(original_Hb2, Hb_predictions2)
  rmse2 <- rmse(original_Hb2, Hb_predictions2)
  
  error.df <- as.data.frame(cbind(original = c(mae,rmse), scaled = c(mae2, rmse2)))
  return(list(results = result.norm,
              comp_plot = comp_plot,
              roc_plot = roc_plot,
              cutpoint = cp,
              error.df = error.df))
}

posterior_plot <- function(fit, params, variables, interval = TRUE) {
  # Plot certain parameter from a stan fit
  posterior <- as.array(fit, pars = params)
  color_scheme_set("red")
  if (interval) {
    plot <- mcmc_intervals(posterior) + scale_y_discrete(labels = variables)
  } else {
    plot <- mcmc_areas(posterior) + scale_y_discrete(labels = variables)
  }
  return(plot)
}


get_params <- function(pars, fit) {
  values <- rstan::extract(fit, pars)
  return(as.data.frame(values))
}


predict_new <- function(model.list, n.samples = 1000, seed) {
  set.seed(seed)
  message("In predict_new function")
  # Input as a list:
  # x: events that we want to predict
  # y: values that we're trying to predict
  # Z: first time measurements of exogenous variables
  # beta: variable coefficients
  # sigmaeps: standard deviation of random error
  # ups: coefficients for first-time exogenous variables
  # sigma_eeta: standard deviation of first event random error
  # sigma_b: standard deviation of donor-specific random effects
  # theta: Slope term for first event donor-specific random effects
  # donor: donor IDs for each measurement
  df <- cbind(model.list$x, y = model.list$y, donor = model.list$donor)
  new_donbs <- matrix(numeric(nrow(df) * 2), ncol = 2)
  
  model.list$sigma_b_mean <- mean(model.list$sigma_b)
  model.list$sigma_epsilon_mean <- mean(model.list$sigma_epsilon)
  model.list$beta_mean <- unname(colMeans(model.list$beta))
  
  if (model.list$type == "dlmm") {
    model.list$theta_mean <- mean(model.list$theta)
    model.list$sigma_eeta_mean <- mean(model.list$sigma_eeta)
    model.list$ups_mean <- unname(colMeans(model.list$ups))
  }
  rowcount <- 1
  model.list$last_events <- integer()
  donors <- unique(df$donor)
  
  for (d in donors) {
    events <- df %>% filter(donor == d) %>% select(-donor)
    n.events <- nrow(events)
    # Note: n.samples is not used for anything here!
    vals <- calculate_donbs(df = events, model.list, donor = d, n.samples = n.samples)
    new_donbs[rowcount:(rowcount + n.events - 1),] <- vals
    rowcount <- rowcount + n.events
    model.list$last_events <- append(model.list$last_events, rowcount - 1)
  }
  model.list$new_donbs <- new_donbs
  if (model.list$type == "dlmm") {
    prediction_matrix <- new_predictions_dlmm(model.list, n.samples=n.samples)
  } else if (model.list$type == "lmm") {
    prediction_matrix <- new_predictions_lmm(model.list, n.samples=n.samples)
  }
  return(list(new_donbs = new_donbs[model.list$last_events,],   # take only donbs for last events
              prediction_matrix = prediction_matrix,  # rows are samples, columns are donors
              last_events = model.list$last_events))  # For each donor gives the integer index of the last donation of that donor
#              predictions = pred.list$predictions,
#              predicted_probabilities = pred.list$predicted_probabilities))
}

# Note: n.samples is not used for anything!
# Input dataframe contains the donations of a single donor.
# Returns a matrix of dimension Nx2, where N is the number of donations of the donor.
# The columns are the mean and sd of the donb
calculate_donbs <- function(df, model.list, donor, n.samples) {
  #message("In calculate_donbs function")
  
  ml <- model.list
  N <- nrow(df)
  new_donbs <- matrix(numeric(N*2), ncol = 2)
  y <- df$y
  df <- df %>% select(-y)
  df <- as.matrix(df)
  for(i in 1:N) {
    # How many time points are we using to estimate don_b?
    time_points <- i - 1
    y_star <- numeric(time_points)
    x_star <- numeric(time_points)
    if (time_points == 0) {
      new_donbs[i,] <- c(0,ml$sigma_b_mean)
    } else if (ml$type == "dlmm") {
      x_star[1] <- ml$theta_mean / ml$sigma_eeta_mean
      y_star[1] <- (y[1] - ml$ups_mean %*% ml$Z[donor,]) / ml$sigma_eeta_mean
      if (time_points > 1) {
        x_star[2:time_points] <- rep(1/ml$sigma_epsilon_mean, time_points - 1)
        y_star[2:time_points] <- (y[2:time_points] - df[2:time_points,] %*% ml$beta_mean) / ml$sigma_epsilon_mean
      }
      dist_mean <- 1/(t(x_star) %*% x_star + ml$sigma_b_mean^(-2)) * (t(x_star) %*% y_star)
      dist_sd <- 1/(t(x_star) %*% x_star + ml$sigma_b_mean^(-2))
      new_donbs[i,] <- c(dist_mean, dist_sd)
    } else if (ml$type == "lmm") {
      x_star[1:time_points] <- rep(1/ml$sigma_epsilon_mean, time_points)
      y_star[1:time_points] <- (y[1:time_points] - df[1:time_points,] %*% ml$beta_mean) / ml$sigma_epsilon_mean
      dist_mean <- 1/(t(x_star) %*% x_star + ml$sigma_b_mean^(-2)) * (t(x_star) %*% y_star)
      dist_sd <- 1/(t(x_star) %*% x_star + ml$sigma_b_mean^(-2))
      new_donbs[i,] <- c(dist_mean, dist_sd)
    }
  }
  return(new_donbs)
}

new_predictions_dlmm <- function(model.list, n.samples = 1000) {
  message("In new_predictions_dlmm function")
  
  ml <- model.list
  N <- nrow(ml$x)
  ml$x <- as.matrix(ml$x)
  C <- ml$C
  #predictions <- c()
  #predicted_probabilities <- c()
  number_of_donors <- length(unique(ml$donor))
  prediction_matrix <- matrix(nrow=n.samples, ncol=number_of_donors)
  #tic(sprintf("Predicting Hb-values for %i donation events using Heckman adjusted LME-model.", N))
  for (i in 1:N) {
    donbs <- rnorm(n.samples, ml$new_donbs[i,1], ml$new_donbs[i,2])
    if (i %in% ml$first_events) {
      preds <- 
        apply(ml$ups,2, function(x) sample(x, size = n.samples, replace = TRUE)) %*% ml$Z[ml$donor[i],] + 
        sample(ml$theta, n.samples, replace = TRUE) * donbs + 
        rnorm(n = n.samples, mean = 0, sd = sample(ml$sigma_eeta, size = n.samples, replace = TRUE))
      if (!is.null(C)) {
        preds <- preds + apply(ml$phi, 2, function(x) sample(x, size = n.samples, replace = TRUE)) %*% ml$C[ml$donor[i],]
      }
    } else {
      preds <- 
        apply(ml$beta, 2, function(x) sample(x, size = n.samples, replace =TRUE)) %*% ml$x[i,] + 
        donbs +
        rnorm(n = n.samples, mean = 0, sd = sample(ml$sigma_epsilon, size = n.samples, replace = TRUE))
      if (!is.null(C)) {
        preds <- preds + apply(ml$phi, 2, function(x) sample(x, size = n.samples, replace = TRUE)) %*% ml$C[ml$donor[i],]
      }
    }
    #predictions[i] <- mean(preds)
    #predicted_probabilities[i] <- length(which(preds < ml$threshold)) / n.samples 
    if (i %in% ml$last_events) {                # We are only interested in predicting the last event of each donor
      #message("Last event")
      prediction_matrix[,ml$donor[i]] <- preds
    }
  }
  #toc()
  # return(list(predictions = predictions,
  #             predicted_probabilities = predicted_probabilities))
  return(prediction_matrix)
}

new_predictions_lmm <- function(model.list, n.samples = 1000) {
  message("In new_predictions_lmm function")
  
  ml <- model.list
  N <- nrow(ml$x)
  ml$x <- as.matrix(ml$x)
  C <- ml$C
  #predictions <- c()
  #predicted_probabilities <- c()
  number_of_donors <- length(unique(ml$donor))
  prediction_matrix <- matrix(nrow=n.samples, ncol=number_of_donors)
  #tic(sprintf("Predicting Hb-values for %i donation events using LME-model without lagged Hb.", N))
  for (i in 1:N) {   # Iterate over all donations
    #message(sprintf("i=%i", i))
    donbs <- rnorm(n.samples, ml$new_donbs[i,1], ml$new_donbs[i,2])
    #message("here1")
    preds <- 
      apply(ml$beta, 2, function(x) sample(x, size = n.samples, replace = TRUE)) %*% ml$x[i,] + 
      donbs +
      rnorm(n = n.samples, mean = 0, sd = sample(ml$sigma_epsilon, size = n.samples, replace = TRUE))
  
    #message("here2")
    if (!is.null(C)) {
      #message("here2.5")
      preds <- preds + apply(ml$phi, 2, function(x) sample(x, size = n.samples, replace = TRUE)) %*% ml$C[ml$donor[i],]
    }
    #message("here3")
    #    predictions[i] <- mean(preds)
#    predicted_probabilities[i] <- length(which(preds < ml$threshold)) / n.samples 
    if (i %in% ml$last_events) {                # We are only interested in predicting the last event of each donor
      #message("Last event")
      prediction_matrix[,ml$donor[i]] <- preds
    }
  }
  #toc()
#  return(list(predictions = predictions,
#              predicted_probabilities = predicted_probabilities))
  return(prediction_matrix)
}



# Function for plotting combined posterior
combine_posterior <- function(fits, params, variables = NULL) {
  posterior <- tibble()
  for (f in fits) {
    # All fits are called "fit" when they are saved
    load(f)
    values <- as_tibble(extract(fit, params))
    posterior <- rbind(posterior, values)
  }
  p.plot <- mcmc_intervals(posterior)
  post.cis <- parameter_cis(posterior)#, pnames = variables)
  if (!is.null(variables)) {p.plot <- p.plot + scale_y_discrete(labels = variables)}
  return(list(posterior = posterior,
              posterior_plot = p.plot,
              cis = post.cis))
}

# Function for combined predictions and analyses
combined_predictions <- function(res.list, threshold = NULL) {
  K <- length(res.list)
  preds <- tibble()
  error.sums <- matrix(numeric(4), nrow = 2)
  for (k in 1:K) {
    preds <- rbind(preds, res.list[[k]]$results)
    error.sums <- error.sums + res.list[[k]]$error.df
  }
  xymin <- min(min(preds$predicted),min(preds$actual))
  xymax <- max(max(preds$predicted),max(preds$actual))
  comp_plot <- ggplot(preds, aes(x = actual, y=predicted, color = deferral)) +
    geom_point() +
    xlim(xymin, xymax) + ylim(xymin, xymax) +
    geom_abline(intercept = 0, slope = 1) +
    labs(x = "observed", y = "predicted", colour = "status") +
    scale_colour_discrete(labels=c("accepted", "deferred"))
  if (!is.null(threshold)) {comp_plot <- comp_plot + 
    geom_vline(xintercept = threshold, linetype = "dashed") + 
    geom_hline(yintercept = threshold, linetype = "dashed")}
  return(list(predictions = preds,
              comp_plot = comp_plot,
              mean_errors = error.sums/K))
} 

---
title: "`r sprintf('Random forest (%s)', params$sex)`"
output: 
  md_document:
  pdf_document:
    keep_tex: true
params:
  input_file: "~/FRCBS/interval_prediction/data/full_data_preprocessed-2020-05-25-train.rdata"
  model: "rf"
  mode: "initial"
  sex: "both"
  id: NULL
  date: "2020-07-08"
  extra_id: NULL
  summary_table_file: NULL
  effect_size_table_file: NULL
  prediction_table_file: NULL
  shap_value_table_file: NULL
  sizes_table_file: NULL
  deferral_age_table_file: NULL
  Hb_cutoff_male: 135
  Hb_cutoff_female: 125
  predictive_variables: NULL
  hyperparameters: "filename"
  cores: 4
  iterations: 2000
  skip_train: FALSE
  compute_shap_values: TRUE
  create_datasets_bool: TRUE
#   donor_specific_file: "~/FRCBS/interval_prediction/data/finngen_snip_prs-2020-07-29.rdata"
  donor_specific_file: NULL
  dev: "cairo_pdf" 
tables: true 
---

```{r, echo=FALSE, message=FALSE}
message(sprintf(">>>>>>>>>> RF %s %s >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>", params$sex, knitr::opts_chunk$get("dev")))
```

<!-- <h2> Initialization </h2> -->
```{r Setup, setup = TRUE, echo=FALSE, message=FALSE, results="hide"}

suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(knitr))
suppressPackageStartupMessages(library(kableExtra))
suppressPackageStartupMessages(library(caret))
suppressPackageStartupMessages(library(tictoc))
suppressPackageStartupMessages(library(entropy))
suppressPackageStartupMessages(library(brms))
suppressPackageStartupMessages(library(ggmcmc))
suppressPackageStartupMessages(library(ggthemes))
suppressPackageStartupMessages(library(ggridges))
suppressPackageStartupMessages(library(ROCR))
suppressPackageStartupMessages(library(pROC))
suppressPackageStartupMessages(library(furrr))
#suppressPackageStartupMessages(library(sn))
suppressPackageStartupMessages(library(tidyverse))
#suppressPackageStartupMessages(library(shapper))
suppressPackageStartupMessages(library(DALEX))
#set.seed(123)


# This can measure time a chunk took to execute.
# Add chunk option time_it=TRUE to each chunk your want to measure.
knitr::knit_hooks$set(time_it = local({
  now <- NULL
  function(before, options) {
    if (before) {
      # record the current time before each chunk
      now <<- lubridate::now()
    } else {
      # calculate the time difference after a chunk
      res <- lubridate::now() - now
      # return a character string to show the time
      msg <- paste("Time for this code chunk to run:", as.numeric(res), units(res))
      message(msg)
      NULL   # Don't return the message so that it won't be printed to the resulting document.
    }
  }
}))


knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, results = "hide", time_it=TRUE)
#knitr::opts_chunk$set(echo=TRUE, message=TRUE)
#options(warn = 1)

if (!is.null(knitr::opts_chunk$get("dev")) && knitr::opts_chunk$get("dev") == "pdf") {
  knitr::opts_chunk$set(dev="cairo_pdf")
  knitr::opts_current$set(dev="cairo_pdf")
}
message(paste0("Device is ", knitr::opts_chunk$get("dev"), "\n"))
message(paste0("Current device is ", knitr::opts_current$get("dev"), "\n"))
use_pdf <- knitr::opts_chunk$get("dev") %in% c("pdf", "cairo_pdf")



options(tinytex.clean = FALSE)  #################### REMOVE THIS !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

message("Parameters are:")
for (name in names(params)) {
  message(sprintf("%s = ", name), params[[name]])
}

mode <- params$mode



source("helper_functions.R")
source("validate_stan_fit.R")
source("enrich_deferrals_rf.R")
source("common.R")

number_of_cores <- set_cores_options(params$cores)

logger <- new_logger(prefix=sprintf("RF %s:", params$sex), file="../output/exclusions.txt", silent=use_pdf)
```

```{r, results="asis", echo=FALSE}
#cat(sprintf("# Random forest (%s)\n", params$sex))
```




```{r Load input data, echo=FALSE}
data <- readRDS(params$input_file) # Forgets the name of the object

data <- data %>%
  mutate(days_to_previous_fb = as.double(days_to_previous_fb),
         donor = as.character(donor))   # For some reason this cannot be a factor



# I use this to pass the "smoking", "bmi", "RNF43_mutant", "prs" to the algorithms
if (!is.null(params$donor_specific_file) && (length(params$donor_specific_file) > 0)) {
  donor_specific_variables <- readRDS(params$donor_specific_file)
  donor_variables <- donor_descript %>% filter(Variable %in% names(donor_specific_variables)) %>% pull(Variable)
  data <- inner_join(data, donor_specific_variables, by="donor")
} else {
  donor_variables = NULL
  donor_specific_variables <- NULL
}



# Make sure the columns in data are in the same order as in the vars list (only needed for stan preprocessing)
variables_in_order <- setdiff(descript$Variable, "donor")
if (!is.null(donor_variables)) {
  data <- data %>% select(all_of(variables_in_order),
                          all_of(donor_variables), everything())
} else {
  data <- data %>% select(all_of(variables_in_order), everything())
}

```



## Data description



### Variables used in prediction

```{r, echo=FALSE, results="markup"}
if (use_pdf) {
  kbl(descript, format="latex", booktabs=TRUE) %>%
  kableExtra::column_spec(1, latex_column_spec = "p{3.2cm}") %>%
  kableExtra::column_spec(2, latex_column_spec = "p{3cm}")   %>%
  kableExtra::column_spec(3, latex_column_spec = "p{2.5cm}") %>%
  kableExtra::column_spec(4, latex_column_spec = "p{6cm}")
} else {
  kbl(descript) %>% kable_styling()
}

if (!is.null(params$donor_specific_file)) {
  kbl(donor_descript %>% filter(Variable %in% c(names(donor_specific_variables), "one_deferral"))) %>% kable_styling()
}
```



```{r Descriptions, results="asis", echo=FALSE}
cat(sprintf("### Summary plots of variables (%s)\n", params$sex))
```


```{r Summary plots, echo = FALSE, eval=TRUE}
res <- create_summary_plots(data, donor_specific_variables, params$sex, descript, donor_descript)
```

```{r, fig.height = 10, fig.width = 7}
res[[1]]
```

```{r}
res[[2]]
```

```{r}
res[[3]]
```

```{r Deferral rate by age}
deferral_age_rates <- compute_deferral_by_age(data)
visualise_deferral_by_age(deferral_age_rates)
Id <- sprintf("%s-%s", params$model, params$sex)
if (!is.null(params$deferral_age_table_file)) {     
  deferral_age_rates <- deferral_age_rates %>% mutate(Id=Id)
  write_csv(deferral_age_rates, params$deferral_age_table_file)   # Pass the table to the web app as well
} 
```


```{r Partition and enrich, echo=FALSE}
debug <- TRUE

donors <- ndonor(data)
message(sprintf("Number of donors is %i\n", length(donors)))
old_count <- nrow(data); old_count2 <- ndonor(data)

tmp <- new_split(data, mode)
train_orig <-tmp$train
test <- tmp$test

msg <- sprintf("Dropped %i / %i donations (%i / %i donors) due to taking training subsample\n", 
              old_count - nrow(train_orig), old_count, old_count2 - ndonor(train_orig), old_count2)
message(msg)
print(logger, msg)
message("Here")
sink(file=stderr(), type="output"); summary(train_orig); sink()
n <- length(unique(train_orig %>% group_by(donor) %>% filter(max(Hb_deferral) == 1) %>% ungroup() %>% pull(donor)))
message(sprintf("%i donors have at least one deferral\n", n))
#message(summary(train_orig))
if (debug) saveRDS(train_orig, file="/tmp/pre-enriched.rds")


message("and here")
```



```{r Process train and validate sets further}


variables <- params$predictive_variables

variables <- c(variables, "Hb_deferral")

if (!is.null(donor_variables)) {
  variables <- c(variables, donor_variables)
}

sizes <- data_counts(train=train_orig, validate=test)
  
#Train

logger2 <- logger
logger2$prefix <- paste(logger$prefix, "train:")
train <- additional_preprocess(train_orig, c(variables, "label"), logger=logger2)    # Label is needed if we will learn hyperparameters.

#Validate
logger2$prefix <- paste(logger$prefix, "test:")
validate <- additional_preprocess(test, c(variables, "Hb", "sex"), logger=logger2) # We want to include Hb and sex to the prediction result table
rm(logger2)


```


```{r Info about datasets, results="asis", echo=FALSE}
msg <- sprintf("The train set contains %i donations from %i donors.", nrow(train), nrow(train))
message(msg)
#cat(msg)
sink(file=stderr(), type="output"); summary(train); sink()

msg <- sprintf("The validate set contains %i donations from %i donors.", nrow(validate), nrow(validate))
message(msg)
#cat(msg)
sink(file=stderr(), type="output"); summary(validate); sink()


train_deferred <- train %>% filter(Hb_deferral == "Deferred")
validate_deferred <- validate %>% filter(Hb_deferral == "Deferred")
#cat(sprintf("The train set contains %i deferrals from %i donors.", nrow(train_deferred), nrow(train_deferred)))
#cat(sprintf("The validate set contains %i deferrals from %i donors.", nrow(validate_deferred), nrow(validate_deferred)))
kbl(sizes) %>% kable_styling()
Id <- sprintf("%s-%s", params$model, params$sex)
if (!is.null(params$sizes_table_file)) {     
  sizes <- sizes %>% mutate(Id=Id)
  write_csv(sizes, params$sizes_table_file)   # Pass the table to the web app as well
} 

rm(train_deferred)
rm(validate_deferred)
saveRDS(train, file=sprintf("/tmp/train1-rf-%s.rds", params$sex))
saveRDS(validate, file=sprintf("/tmp/validate1-rf-%s.rds", params$sex))
```




```{r Train random forest, message=FALSE}
number_of_accepted  <- train %>% filter(Hb_deferral=="Accepted") %>% nrow()
number_of_deferrals <- train %>% filter(Hb_deferral=="Deferred") %>% nrow()
message("here1")
if (number_of_accepted == 0 || number_of_deferrals == 0) {
  stop(sprintf("Not all classes are present in the train data:\nnumber of deferrals = %i, number of accepted = %i\n", number_of_deferrals,
               number_of_accepted), call.=FALSE)
}
tic("Training random forest")

# Read or learn hyperparameters
message("here2")
hyperparameters <- read_hyperparameters(params$hyperparameters)
message("here3")
rf_hyperparameters <- hyperparameters %>% filter(Model=="rf", Sex==params$sex) %>% pull(Value)
message("here4")
rf_method <- "ranger"  # This uses ranger::ranger
#rf_method <- "rf"     # This uses randomForest::randomForest
if (rf_method == "ranger") {
  strata <- NULL
  sampsize <- NULL
} else {
  strata <- train$Hb_deferral
  sampsize <- sum(train$Hb_deferral == "Accepted")   # oversample to the count of the most common class
}

if (length(rf_hyperparameters) == 0) {   # Hyperparameters not available for this model yet
  #https://stats.stackexchange.com/questions/158583/what-does-node-size-refer-to-in-the-random-forest/
  #max.depth =c(1:10) # this is not available
  #Define search grid
  quick <- FALSE
  if (quick) {
    # Small grid for testing purposes
    mtry = c(3:5)     
    min.node.size = seq(30,40)
    num.trees = 500
    splitrule=c("extratrees","hellinger")
  } else {
    # 2022-02-03:
    #mtry <- c(3)
    mtry <- c(3:8)
    #min.node.size <- seq(1, 501, 50)
    min.node.size <- seq(1, 5001, 250)
    splitrule=c("gini", "extratrees","hellinger")
    # 2022-02-01:
    # min.node.size <- seq(1, 101, 10)
    # splitrule=c("gini", "extratrees","hellinger")
    num.trees <- 500
  }
  if (rf_method == "ranger") {
    rf_grid <-  expand.grid(
      mtry = mtry,
      min.node.size = min.node.size,
      num.trees = num.trees,
      splitrule=splitrule
    )
  } else {
    rf_grid <-  expand.grid(
      mtry = mtry,
      nodesize = min.node.size,  # Minimum node size
      ntree = num.trees
    )
  }
  
  set.seed(global_random_seed)
  ret <- learn_hyperparameters(df = train, 
                               method = rf_method,
                               search_grid = rf_grid, 
                               cores = number_of_cores,
                               strata=strata,
                               sampsize=sampsize,
                               replace=TRUE)
  rf_hyperparameters <- as.list(ret$bestTune)
  hyperparameters <- hyperparameters %>% add_row(Model="rf", Sex=params$sex, Value=list(rf_hyperparameters))
  write_hyperparameters(hyperparameters, params$hyperparameters)
  hyper_fit_filename <- sprintf("/tmp/rf-hyper-fit-%s.rds", params$sex)
  saveRDS(ret, hyper_fit_filename)
} else {
  rf_hyperparameters <- rf_hyperparameters[[1]]
}
message("here5")

train <- train %>% select(-label)   # Not needed anymore

message("here6")

train    <- train    %>% mutate(across(any_of(c("warm_season", "previous_Hb_def")), as.integer))   ## POISTA, vain testausta varten 
validate <- validate %>% mutate(across(any_of(c("warm_season", "previous_Hb_def")), as.integer))   ## POISTA, vain testatusta varten 
message("here7")

saveRDS(train, file=sprintf("/tmp/rf-train-%s.rds", params$sex))
saveRDS(validate, file=sprintf("/tmp/rf-validate-%s.rds", params$sex))
message("here8")

fit_filename <- sprintf("/tmp/rf-fit-%s.rds", params$sex)
if (use_pdf) {
  rrfFit_roc <- readRDS(fit_filename)
} else {
  set.seed(global_random_seed)
  #n <- as.integer(sum(train$Hb_deferral == "Accepted"))  # oversample to the count of the most common class

  # If formula is given as the first parameter, then the variables get recoded and renamed:
  # https://stackoverflow.com/questions/30097730/error-when-using-predict-on-a-randomforest-object-trained-with-carets-train
  #rrfFit_roc <- caret::train(Hb_deferral ~ ., data = train, 
  message("here9")
  rrfFit_roc <- caret::train(x = as.data.frame(train %>% select(-Hb_deferral)), y = train %>% pull(Hb_deferral),
                             method = rf_method, 
                             strata=strata,
                             sampsize=sampsize,  
                             # I start to think that this doesn't do stratified sampling.
                                          # For it 'samplesize=(n, n)' should be used, but the algorithm
                                          # doesn't allow oversampling, event if replace==TRUE. See
                                          # https://stats.stackexchange.com/questions/45705/sampling-with-replacement-in-r-randomforest
                             replace=TRUE,
                             #nodesize=34,
                             trControl = caret::trainControl(method="none", classProbs = TRUE, sampling="smote"), 
                             verbose = FALSE, 
                             ## Now specify the exact models 
                             ## to evaluate:
                             #tuneLength=1,
                             tuneGrid = as_tibble(rf_hyperparameters),
                             #tuneGrid = tibble(mtry=3, splitrule="gini", min.node.size=10),
                             #metric="ROC",
                             #should we use Kappa or ROC?
                             importance = if (rf_method == "rf") TRUE else "permutation"
                             #https://stackoverflow.com/questions/18578861/variable-importance-using-the-caret-package-error-randomforest-algorithm
                             #should we use , ’impurity’, ’impurity_corrected’, ’permutation’ ?
  )
  message("here10")

  sink(file=stderr(), type="output"); toc(); sink()
  saveRDS(rrfFit_roc, fit_filename)
}

```






## Results


```{r SHAP values, eval=params$compute_shap_values}
message(paste(colnames(train), collapse=" "))
message(paste(colnames(validate), collapse=" "))

#Id <- sprintf("%s-%s", params$model, params$sex)
shap_filename <- sprintf("/tmp/shap_values_%s_%s.rds", params$model, params$sex)
if (use_pdf) {     
  res <- readRDS(shap_filename)   # Already computed when creating png from the Rmd
} else {
  res <- compute_shap_values_fastshap(rrfFit_roc$finalModel, validate, variables, seed=global_random_seed)
  res <- res %>% mutate(Id=Id)
  saveRDS(res, shap_filename)
}

if (!is.null(res)) {
  
  if (!is.null(params$shap_value_table_file)) {
    write_csv(res, params$shap_value_table_file)   # Pass the table to the web app as well
  }
  
  variables_renamed <- FALSE
  
  shap_plot_rf <- plot_summary_shap_values(res, variables_renamed)
  shap_plot_rf2 <- plot_shap_values(res, variables_renamed)
  plot(shap_plot_rf)
  plot(shap_plot_rf2)
}
```

```{r Create variable importances plot}
rrfFit_rocImp <- caret::varImp(rrfFit_roc, scale = FALSE)
rf_variable_importances <- rownames_to_column(rrfFit_rocImp$importance)
colnames(rf_variable_importances) <- c("Variable", "Importance")
rf_variable_importances <- left_join(rf_variable_importances, bind_rows(descript, donor_descript), by=c("Variable"="Variable")) %>% 
  select(Variable, Pretty, Importance) %>% 
  arrange(Importance)

message(paste(rf_variable_importances$Variable, collapse=" "))

# Fix some pretty variables names

variables_renamed <- FALSE
rf_variable_importances <- prettify_variables(rf_variable_importances, variables_renamed)

if (!is.null(params$effect_size_table_file)) {
  write_csv(rf_variable_importances, params$effect_size_table_file)   # Pass the table to the web app as well
}

rf_variable_importances_plot <- rf_variable_importances %>%
  ggplot() + 
  geom_col(aes(y=Importance, x=reorder(Pretty, Importance)), alpha=0.7) + 
  coord_flip() + 
  xlab("Variable")

rf_variable_importances_plot
```


```{r Predict deferral classes and probabilities}

# Predicted labels
prediction_train_labels    <- predict(rrfFit_roc, newdata = train)
prediction_validate_labels <- predict(rrfFit_roc, newdata = validate)
# Predicted probabilities
prediction_train_probs    <- as.data.frame(predict(rrfFit_roc, newdata = train, type="prob"))
prediction_validate_probs <- as.data.frame(predict(rrfFit_roc, newdata = validate, type="prob"))


```

```{r Optimize cutpoint, results="asis"}
# Find the threshold for probability that maximizes the F1 score
cp <- get_optimal_cut_point(prediction_train_probs$Deferred, train$Hb_deferral)
cp_validate <- get_optimal_cut_point(prediction_validate_probs$Deferred, validate$Hb_deferral)

cp_filename <- sprintf("/tmp/cut_point_%s_%s.rds", params$model, params$sex)
saveRDS(cp, cp_filename)

f1_threshold <- cp$optimal_cutpoint
cat(sprintf("Train data F1 threshold is %.3f, FPR is %.3f, TPR is %.3f\n", f1_threshold, 1-cp$specificity, cp$sensitivity))
sink(file=stderr(), type="output"); cp; sink()
```

### Train data cutoff plot

```{r}
summary(cp)
plot(cp)
plot_metric(cp, conf_lvl = 0.95)
```

### Validation data cutoff plot

```{r}
summary(cp_validate)
plot(cp_validate)
plot_metric(cp_validate, conf_lvl = 0.95)
```



```{r Create prediction result dataframe, warning=FALSE, echo=FALSE}
source("validate_stan_fit.R")
#id <- sprintf("rf-%s", params$sex)
df <- tibble(
  id=Id,
  model="rf",
  sex=validate$sex,
  original_label = ifelse(validate$Hb_deferral == "Deferred", 1, 0), 
  predicted_label = ifelse(prediction_validate_labels == "Deferred", 1, 0), 
  score=prediction_validate_probs$Deferred,
  f1_threshold = f1_threshold,
  score_predicted_label = as.integer(score >= f1_threshold),
  original_value=validate$Hb,
  predicted_value=NA)
sink(file=stderr(), type="output"); summary(df %>% mutate(across(c("original_label", "predicted_label"), as.factor))); sink()
if (!is.null(params$prediction_table_file)) {
  write_csv(df, params$prediction_table_file)   # Pass the table to the web app as well
}
```


```{r Show random forest results, echo=FALSE}

number_of_deferrals <- validate %>% filter(Hb_deferral=="Accepted") %>% nrow()
number_of_accepted <- validate %>% filter(Hb_deferral=="Deferred") %>% nrow()
if (number_of_accepted == 0 || number_of_deferrals == 0) {
  stop(sprintf("Not all classes are present in the validation data:\nnumber of deferrals = %i, number of accepted = %i\n", number_of_deferrals,
               number_of_accepted), call.=FALSE)
}

message("Here1")
results_both_random_forest <- gather_results(df, Id=Id, Model = "rf", Pretty="Random forest", Sex=params$sex, f1_threshold = f1_threshold)

results_both_random_forest$confusion_matrix_plot
results_both_random_forest$roc_plot 
message("Here4")
results_both_random_forest$pr_plot
message("Here5")
results_both_random_forest$f1_ci
message("Here6")
#print(t)
message("Here8")
summary_table <- results_both_random_forest$summary
message("Here9")

```









### Summary

```{r Summary table, results="markup"}

if (!is.null(params$summary_table_file)) {
  write_csv(summary_table, params$summary_table_file)   # Pass the table to the web app as well
}

```

```{r Show summary table, results="markup"}
cols <- c("Model"="Pretty", "Sex", "AUROC" = "AUROC value", "AUPR" = "AUPR value", "F1" = "F1 value")
kbl(summary_table %>% select(!!!cols), digits=3, format.args = list(digits=3)) %>% kable_styling()
```

```{r Print the sizes of global objects, echo=FALSE}
get_global_object_sizes <- function() {
  s <- lobstr::obj_sizes(!!!as.list(rlang::global_env()))
  t <- tibble(object=names(s), bytes=as.numeric(s), isfunction=map_lgl(object, ~ is.function(get(.x))))
  return(arrange(t, isfunction, desc(bytes)))
}

msg <- capture.output(print(get_global_object_sizes(), n=Inf))
message(paste(msg, collapse="\n"))
#msg <- capture.output(lobstr::obj_sizes(!!!as.list(rlang::global_env())))
#message(paste(msg, collapse="\n"))
```


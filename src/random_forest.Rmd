---
#title: "Subset analyses"
output: md_document
params:
  input_file: "~/FRCBS/interval_prediction/data/full_data_preprocessed-2020-05-25-train.rdata"
  hlen: NULL
  hlen_exactly: FALSE
  sample_fraction: 1.0
  model: "rf"
  mode: "initial"
  sex: "both"
  id: NULL
  date: "2020-07-08"
  extra_id: NULL
  summary_table_file: NULL
  effect_size_table_file: NULL
  prediction_table_file: NULL
  shap_value_table_file: NULL
  Hb_cutoff_male: 135
  Hb_cutoff_female: 125
  predictive_variables: NULL
  hyperparameters: "filename"
  cores: 4
  iterations: 2000
  skip_train: FALSE
  compute_shap_values: TRUE
  create_datasets_bool: TRUE
#   donor_specific_file: "~/FRCBS/interval_prediction/data/finngen_snip_prs-2020-07-29.rdata"
  donor_specific_file: NULL
  dev: "cairo_pdf"  
---

```{r, echo=FALSE, message=FALSE}
message(sprintf(">>>>>>>>>> RF %s %s >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>", params$sex, knitr::opts_chunk$get("dev")))
```

<!-- <h2> Initialization </h2> -->
```{r Setup, setup = TRUE, echo=FALSE, message=FALSE, results="hide"}

suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(knitr))
#library(rstan)
suppressPackageStartupMessages(library(caret))
suppressPackageStartupMessages(library(tictoc))
suppressPackageStartupMessages(library(entropy))
suppressPackageStartupMessages(library(brms))
suppressPackageStartupMessages(library(ggmcmc))
suppressPackageStartupMessages(library(ggthemes))
suppressPackageStartupMessages(library(ggridges))
suppressPackageStartupMessages(library(ROCR))
suppressPackageStartupMessages(library(pROC))
suppressPackageStartupMessages(library(furrr))
suppressPackageStartupMessages(library(sn))
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(shapper))
suppressPackageStartupMessages(library(DALEX))
#set.seed(123)


# This can measure time a chunk took to execute.
# Add chunk option time_it=TRUE to each chunk your want to measure.
knitr::knit_hooks$set(time_it = local({
  now <- NULL
  function(before, options) {
    if (before) {
      # record the current time before each chunk
      now <<- lubridate::now()
    } else {
      # calculate the time difference after a chunk
      res <- lubridate::now() - now
      # return a character string to show the time
      msg <- paste("Time for this code chunk to run:", as.numeric(res), units(res))
      message(msg)
      NULL   # Don't return the message so that it won't be printed to the resulting document.
    }
  }
}))


knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, results = "hide", time_it=TRUE)
#knitr::opts_chunk$set(echo=TRUE, message=TRUE)
#options(warn = 1)

if (knitr::opts_chunk$get("dev") == "pdf") {
  knitr::opts_chunk$set(dev="cairo_pdf")
  knitr::opts_current$set(dev="cairo_pdf")
}
message(paste0("Device is ", knitr::opts_chunk$get("dev"), "\n"))
message(paste0("Current device is ", knitr::opts_current$get("dev"), "\n"))
use_pdf <- knitr::opts_chunk$get("dev") %in% c("pdf", "cairo_pdf")

message("Parameters are:")
for (name in names(params)) {
  message(sprintf("%s = ", name), params[[name]])
}

mode <- params$mode



#set.seed(123)
number_of_cores <- parallel::detectCores()
if (!is.null(params$cores)) {
  number_of_cores <- min(params$cores, number_of_cores)
  options(mc.cores   = number_of_cores)   # This option is in package parallel
  options(boot.ncpus = number_of_cores)   # For bootstrapping
} else {
  options(mc.cores   = number_of_cores)
  options(boot.ncpus = number_of_cores)
}
#rstan_options(auto_write = TRUE) # To avoid recompilation of unchanged Stan programs, we recommend calling




source("helper_functions.R")
source("validate_stan_fit.R")
source("enrich_deferrals_rf.R")
source("common.R")

logger <- new_logger(prefix=sprintf("RF %s:", params$sex), file="../output/exclusions.txt", silent=use_pdf)
```

```{r, results="asis", echo=FALSE}
cat(sprintf("# Random forest (%s)\n", params$sex))
```




```{r Load input data, echo=FALSE}
data <- readRDS(params$input_file) # Forgets the name of the object
#data <- load_single("~/FRCBS/Hb_predictor_container/output/preprocessed.rdata")

data <- data %>%
  mutate(days_to_previous_fb = as.double(days_to_previous_fb),
         donor = as.character(donor))   # For some reason this cannot be a factor



# I use this to pass the "smoking", "bmi", "RNF43_mutant", "prs" to the algorithms
if (!is.null(params$donor_specific_file) && (length(params$donor_specific_file) > 0)) {
  donor_specific_variables <- readRDS(params$donor_specific_file)
  donor_variables <- donor_descript %>% filter(Variable %in% names(donor_specific_variables)) %>% pull(Variable)
  data <- inner_join(data, donor_specific_variables, by="donor")
} else {
  donor_variables = NULL
  donor_specific_variables <- NULL
}



# Make sure the columns in data are in the same order as in the vars list (only needed for stan preprocessing)
variables_in_order <- setdiff(descript$Variable, "donor")
if (!is.null(donor_variables)) {
  data <- data %>% select(all_of(variables_in_order),
                          all_of(donor_variables), everything())
} else {
  data <- data %>% select(all_of(variables_in_order), everything())
}



```



## Data description



### Variables used in prediction

```{r, echo=FALSE, results="markup"}
kable(descript)
if (!is.null(params$donor_specific_file)) {
  kable(donor_descript %>% filter(Variable %in% c(names(donor_specific_variables), "one_deferall")))
}
```



```{r Descriptions, results="asis", echo=FALSE}
cat(sprintf("### Summary plots of variables (%s)\n", params$sex))
```


```{r Summary plots, echo = FALSE, eval=TRUE}
create_summary_plots(data, donor_specific_variables, params$sex, descript, donor_descript)
```





```{r Partition and enrich, echo=FALSE}
debug <- TRUE

donors <- ndonor(data)
message(sprintf("Number of donors is %i\n", length(donors)))
old_count <- nrow(data); old_count2 <- ndonor(data)

#tmp <- old_split(data)
tmp <- new_split(data, mode)
train_orig <-tmp$train
test <- tmp$test

msg <- sprintf("Dropped %i / %i donations (%i / %i donors) due to taking training subsample\n", 
              old_count - nrow(train_orig), old_count, old_count2 - ndonor(train_orig), old_count2)
message(msg)
print(logger, msg)
message("Here")
sink(file=stderr(), type="output"); summary(train_orig); sink()
n <- length(unique(train_orig %>% group_by(donor) %>% filter(max(Hb_deferral) == 1) %>% ungroup() %>% pull(donor)))
message(sprintf("%i donors have at least one deferral\n", n))
#message(summary(train_orig))
if (debug) saveRDS(train_orig, file="/tmp/pre-enriched.rds")

# enrich the data so that 50% of the donors have deferral as their last donation attempt
old_count <- nrow(train_orig); old_count2 <- ndonor(train_orig)
#sink(file=stderr(), type="output")
if (old_count2 >= 1000) {
  enriched <- enrich_deferrals_rf(train_orig, 0.5, seed=global_random_seed)  # truncates time series
  #sink()
  msg <- sprintf("Dropped %i / %i donations (%i / %i donors) due to enrichment\n", 
                  old_count - nrow(enriched), old_count, old_count2 - ndonor(enriched), old_count2)
  message(msg)
  print(logger, msg)
  if (debug) saveRDS(enriched, file="/tmp/post-enriched.rds")
} else {  # Don't enrich if less than 1000 donors
  message(sprintf("Skipped enrichment of train data, since number of donors %i is less than %i", old_count2, 1000))
  enriched <- train_orig
}

n <- length(unique(enriched %>% group_by(donor) %>% filter(max(Hb_deferral) == 1) %>% ungroup() %>% pull(donor)))
message(sprintf("%i donors have at least one deferral\n", n))

# Drop donors whose last ferritin is not measured before the last blood donation after the truncation
if ("FERRITIN_LAST_DATE" %in% names(enriched)) {
  old_count <- nrow(enriched); old_count2 <- ndonor(enriched)
  enriched <- enriched %>% 
    group_by(donor) %>% 
    mutate(last_donation_date = max(dateonly)) %>% 
    ungroup() %>% 
    filter(FERRITIN_LAST_DATE < last_donation_date)  %>% 
    select(-last_donation_date)
  msg <- sprintf("Dropped %i / %i donations (%i / %i donors) due to FERRITIN_LAST_DATE not being before last blood donation\n", 
              old_count - nrow(enriched), old_count, old_count2 - ndonor(enriched), old_count2)
  message(msg)
  print(logger, msg)
}
sink(file=stderr(), type="output"); summary(enriched); sink()
if (debug) saveRDS(enriched, file="/tmp/enriched.rds")
#enriched <- enriched %>% select(-FERRITIN_LAST_DATE)
#rm(train_orig)

message("and here")
```



```{r Process train and validate sets further}
# variables <- c(
#                "days_to_previous_fb", 
#                "age", 
#                "previous_Hb_def",
#                year, #CHECK! 
#                "warm_season", 
#                "consecutive_deferrals", 
#                "recent_donations",
#                "recent_deferrals", 
#                "hour", 
#                "previous_Hb", 
#                "Hb_first")

variables <- params$predictive_variables

variables <- c(variables, 
               c(
               "Hb_deferral",
               "nb_donat"))

if (!is.null(donor_variables)) {
  variables <- c(variables, donor_variables)
}
  
#Train

train <- additional_preprocess(enriched, c(variables, "label"))    # Label is needed if we will learn hyperparameters.

#Validate

validate <- additional_preprocess(test, c(variables, "Hb", "sex")) # We want to include Hb and sex to the prediction result table



```


```{r Info about datasets, results="asis", echo=FALSE}
msg <- sprintf("The train set contains %i donations from %i donors.", nrow(train), nrow(train))
message(msg)
cat(msg)
sink(file=stderr(), type="output"); summary(train); sink()

msg <- sprintf("The validate set contains %i donations from %i donors.", nrow(validate), nrow(validate))
message(msg)
cat(msg)
sink(file=stderr(), type="output"); summary(validate); sink()


train_deferred <- train %>% filter(Hb_deferral == "Deferred")
validate_deferred <- validate %>% filter(Hb_deferral == "Deferred")
cat(sprintf("The train set contains %i deferrals from %i donors.", nrow(train_deferred), nrow(train_deferred)))
cat(sprintf("The validate set contains %i deferrals from %i donors.", nrow(validate_deferred), nrow(validate_deferred)))
rm(train_deferred)
rm(validate_deferred)
```




```{r Train random forest, message=FALSE}
number_of_accepted  <- train %>% filter(Hb_deferral=="Accepted") %>% nrow()
number_of_deferrals <- train %>% filter(Hb_deferral=="Deferred") %>% nrow()
# stopifnot(number_of_deferrals > 0)
# stopifnot(number_of_accepted > 0)
if (number_of_accepted == 0 || number_of_deferrals == 0) {
  stop(sprintf("Not all classes are present in the train data:\nnumber of deferrals = %i, number of accepted = %i\n", number_of_deferrals,
               number_of_accepted), call.=FALSE)
}
tic("Training random forest")

# Read or learn hyperparameters
hyperparameters <- read_hyperparameters(params$hyperparameters)
rf_hyperparameters <- hyperparameters %>% filter(Model=="rf", Sex==params$sex) %>% pull(Value)
if (length(rf_hyperparameters) == 0) {   # Hyperparameters not available for this model yet
  #Define search grid
  quick <- FALSE
  if (quick) {
    # Small grid for testing purposes
    rf_grid <-  expand.grid(
      mtry = c(3:5),
      splitrule=c("extratrees","hellinger"),
      min.node.size = seq(30,40)
    )
  } else {
    rf_grid <-  expand.grid(
      mtry = c(3:8),
      splitrule=c("gini", "extratrees","hellinger"),
      #min.node.size = seq(3,39,3) #what kind of range is needed?
      min.node.size = seq(1, 60, 5)
      #https://stats.stackexchange.com/questions/158583/what-does-node-size-refer-to-in-the-random-forest/
      #max.depth =c(1:10) # this is not available
    )
  }
    
  set.seed(global_random_seed)
  rf_hyperparameters <- learn_hyperparameters(train, "ranger", rf_grid, number_of_cores)
  hyperparameters <- hyperparameters %>% add_row(Model="rf", Sex=params$sex, Value=list(rf_hyperparameters))
  write_hyperparameters(hyperparameters, params$hyperparameters)
} else {
  rf_hyperparameters <- rf_hyperparameters[[1]]
}

train <- train %>% select(-label)   # Not needed anymore

if (nrow(train) <= rf_hyperparameters$min.node.size) {
  message("Warning: There are less points in the train data than what is the min.node.size of the random forest")
  warning(sprintf("There are less points in the train data (%i) than what is the min.node.size of the random forest(%i)",
                  nrow(train), rf_hyperparameters$min.node.size))
}

train    <- train    %>% mutate(across(intersect(c("warm_season", "previous_Hb_def"), names(train)), as.integer))   ## POISTA, vain testatusta varten 
validate <- validate %>% mutate(across(intersect(c("warm_season", "previous_Hb_def"), names(validate)), as.integer))   ## POISTA, vain testatusta varten 

saveRDS(train, file=sprintf("/tmp/rf-train-%s.rds", params$sex))
saveRDS(validate, file=sprintf("/tmp/rf-validate-%s.rds", params$sex))

fit_filename <- sprintf("/tmp/rf-fit-%s.rds", params$sex)
if (use_pdf) {
  rrfFit_roc <- readRDS(fit_filename)
} else {
  set.seed(global_random_seed)
  # If formula is given as the first parameter, then the variables get recoded and renamed:
  # https://stackoverflow.com/questions/30097730/error-when-using-predict-on-a-randomforest-object-trained-with-carets-train
  #rrfFit_roc <- caret::train(Hb_deferral ~ ., data = train, 
  rrfFit_roc <- caret::train(x = as.data.frame(train %>% select(-Hb_deferral)), y = train %>% pull(Hb_deferral),
                             method = "ranger", 
                             trControl = caret::trainControl(method="none", classProbs = TRUE), 
                             verbose = FALSE, 
                             ## Now specify the exact models 
                             ## to evaluate:
                             #tuneLength=1,
                             tuneGrid = as_tibble(rf_hyperparameters),
                             #tuneGrid = tibble(mtry=3, splitrule="gini", min.node.size=10),
                             #metric="ROC",
                             #should we use Kappa or ROC?
                             importance = "permutation"
                             #https://stackoverflow.com/questions/18578861/variable-importance-using-the-caret-package-error-randomforest-algorithm
                             #should we use , ’impurity’, ’impurity_corrected’, ’permutation’ ?
  )
  
  sink(file=stderr(), type="output"); toc(); sink()
  saveRDS(rrfFit_roc, fit_filename)
}

write_csv(train, '../output/train.csv')
write_csv(validate, '../output/validate.csv')

```






## Results


```{r SHAP values, eval=params$compute_shap_values}
message(paste(colnames(train), collapse=" "))
message(paste(colnames(validate), collapse=" "))


shap_filename <- sprintf("/tmp/shap_values_%s_%s.rds", params$model, params$sex)
if (use_pdf) {     
  res <- readRDS(shap_filename)   # Already computed when creating png from the Rmd
} else {
  #res <- compute_shap_values_shapper(rrfFit_roc$finalModel, train, validate, variables)
  res <- compute_shap_values_shapr(rrfFit_roc$finalModel, validate, variables, seed=global_random_seed)
  saveRDS(res, shap_filename)
}

if (!is.null(res)) {
  
  if (!is.null(params$shap_value_table_file)) {
    write_csv(res, params$shap_value_table_file)   # Pass the table to the web app as well
  }
  
  variables_renamed <- FALSE
  
  shap_plot_rf <- plot_summary_shap_values(res, variables_renamed)
  shap_plot_rf2 <- plot_shap_values(res, variables_renamed)
  #ive_rf <- shapper::shap(exp_rf, new_observation = validate2[1,], nsamples=50)
  #plot(ive_rf)
  plot(shap_plot_rf)
  plot(shap_plot_rf2)
}
```

```{r Create variable importances plot}
rrfFit_rocImp <- caret::varImp(rrfFit_roc, scale = FALSE)
#plot(rrfFit_rocImp)


#rrfFit.varimp <- as_tibble(cbind(rownames(rrfFit_rocImp$importance), rrfFit_rocImp$importance))
rf_variable_importances <- rownames_to_column(rrfFit_rocImp$importance)  # Cleaner than above
colnames(rf_variable_importances) <- c("Variable", "Importance")
rf_variable_importances <- left_join(rf_variable_importances, bind_rows(descript, donor_descript), by=c("Variable"="Variable")) %>% 
  select(Variable, Pretty, Importance) %>% 
  arrange(Importance)

message(paste(rf_variable_importances$Variable, collapse=" "))

# Fix some pretty variables names

variables_renamed <- FALSE
rf_variable_importances <- prettify_variables(rf_variable_importances, variables_renamed)

if (!is.null(params$effect_size_table_file)) {
  write_csv(rf_variable_importances, params$effect_size_table_file)   # Pass the table to the web app as well
}

rf_variable_importances_plot <- rf_variable_importances %>%
  ggplot() + 
  geom_col(aes(y=Importance, x=reorder(Pretty, Importance)), alpha=0.7) + 
  coord_flip() + 
  xlab("Variable")

#filename="../results/rrfFit_roc_importance.pdf"
#ggsave(filename=filename, varimp.plot, width = 180,  height = 80,units="mm", dpi=600, scale=1.0)
rf_variable_importances_plot
```


```{r Predict deferral classes and probabilities}
# prediction_vl <- predict(rrfFit_roc, newdata = validate)
# prediction_probs <- predict(rrfFit_roc, newdata = validate, type="prob")


train$pred <- predict(rrfFit_roc, newdata = train)
prediction_vl <- predict(rrfFit_roc, newdata = validate)
prediction_probs <- as.data.frame(predict(rrfFit_roc, newdata = validate, type="prob"))

write_csv(train, '../output/predtrain.csv')
write_csv(as.data.frame(prediction_vl), '../output/predvl.csv')
write_csv(prediction_probs, '../output/predprobs.csv')
```



```{r Create prediction result dataframe, warning=FALSE, echo=FALSE}
source("validate_stan_fit.R")
id <- sprintf("rf-%s", params$sex)
df <- tibble(
  id=id,
  model="rf",
  sex=validate$sex,
  original_label = ifelse(validate$Hb_deferral == "Deferred", 1, 0), 
  predicted_label = ifelse(prediction_vl == "Deferred", 1, 0), 
  score=prediction_probs$Deferred,
  original_value=validate$Hb,
  predicted_value=NA)
sink(file=stderr(), type="output"); summary(df %>% mutate_at(c("original_label", "predicted_label"), as.factor)); sink()
if (!is.null(params$prediction_table_file)) {
  write_csv(df, params$prediction_table_file)   # Pass the table to the web app as well
}
```


```{r Show random forest results, echo=FALSE}

number_of_deferrals <- validate %>% filter(Hb_deferral=="Accepted") %>% nrow()
number_of_accepted <- validate %>% filter(Hb_deferral=="Deferred") %>% nrow()
# stopifnot(number_of_deferrals > 0)
# stopifnot(number_of_accepted > 0)
if (number_of_accepted == 0 || number_of_deferrals == 0) {
  stop(sprintf("Not all classes are present in the validation data:\nnumber of deferrals = %i, number of accepted = %i\n", number_of_deferrals,
               number_of_accepted), call.=FALSE)
}

message("Here1")
results_both_random_forest <- gather_results(df, Id=id, Model = "rf", Pretty="Random forest", Sex=params$sex)

results_both_random_forest$confusion_matrix_plot
results_both_random_forest$roc_plot 
message("Here4")
results_both_random_forest$pr_plot
message("Here5")
results_both_random_forest$f1_ci
message("Here6")
#print(t)
message("Here8")
#summary_rows[[length(summary_rows)+1]] <- results_both_random_forest$summary
summary_table <- results_both_random_forest$summary
message("Here9")

```









### Summary

```{r Summary table, results="markup"}

if (!is.null(params$summary_table_file)) {
  write_csv(summary_table, params$summary_table_file)   # Pass the table to the web app as well
}

```

```{r Show summary table, results="markup"}
cols <- c("Model"="Pretty", "Sex", "MAE (g / L)", "RMSE (g / L)", "MAE (mmol / L)", "RMSE (mmol / L)", "AUROC" = "AUROC value", "AUPR" = "AUPR value", "F1" = "F1 value")
kable(summary_table %>% select(!!!cols), digits=3, format.args = list(digits=3))
```
